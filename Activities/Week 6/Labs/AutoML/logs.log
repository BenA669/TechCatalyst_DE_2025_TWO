2025-08-08 15:04:00,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 15:04:00,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 15:04:00,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 15:04:00,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-08 15:04:07,671:INFO:PyCaret ClassificationExperiment
2025-08-08 15:04:07,672:INFO:Logging name: clf-default-name
2025-08-08 15:04:07,672:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-08 15:04:07,672:INFO:version 3.3.2
2025-08-08 15:04:07,672:INFO:Initializing setup()
2025-08-08 15:04:07,672:INFO:self.USI: 5d1e
2025-08-08 15:04:07,672:INFO:self._variable_keys: {'seed', 'log_plots_param', 'exp_name_log', 'gpu_n_jobs_param', 'logging_param', 'X', 'html_param', 'exp_id', 'gpu_param', 'y_test', 'fold_shuffle_param', 'memory', 'fold_generator', 'fold_groups_param', 'data', 'n_jobs_param', 'X_train', '_available_plots', 'y_train', 'idx', 'target_param', 'pipeline', 'fix_imbalance', 'USI', '_ml_usecase', 'X_test', 'y', 'is_multiclass'}
2025-08-08 15:04:07,672:INFO:Checking environment
2025-08-08 15:04:07,672:INFO:python_version: 3.11.13
2025-08-08 15:04:07,672:INFO:python_build: ('main', 'Jul 11 2025 22:36:59')
2025-08-08 15:04:07,672:INFO:machine: AMD64
2025-08-08 15:04:07,672:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-08 15:04:07,681:INFO:Memory: svmem(total=17111728128, available=3737448448, percent=78.2, used=13374279680, free=3737448448)
2025-08-08 15:04:07,682:INFO:Physical Core: 8
2025-08-08 15:04:07,682:INFO:Logical Core: 16
2025-08-08 15:04:07,682:INFO:Checking libraries
2025-08-08 15:04:07,682:INFO:System:
2025-08-08 15:04:07,682:INFO:    python: 3.11.13 (main, Jul 11 2025, 22:36:59) [MSC v.1944 64 bit (AMD64)]
2025-08-08 15:04:07,682:INFO:executable: c:\Users\Benja\Documents\Projects\techcat\py311\Scripts\python.exe
2025-08-08 15:04:07,682:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-08 15:04:07,682:INFO:PyCaret required dependencies:
2025-08-08 15:04:07,683:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:04:15,635:INFO:                 pip: Not installed
2025-08-08 15:04:15,635:INFO:          setuptools: 80.9.0
2025-08-08 15:04:15,635:INFO:             pycaret: 3.3.2
2025-08-08 15:04:15,635:INFO:             IPython: 9.4.0
2025-08-08 15:04:15,635:INFO:          ipywidgets: 8.1.7
2025-08-08 15:04:15,635:INFO:                tqdm: 4.67.1
2025-08-08 15:04:15,636:INFO:               numpy: 1.26.4
2025-08-08 15:04:15,636:INFO:              pandas: 2.1.4
2025-08-08 15:04:15,636:INFO:              jinja2: 3.1.6
2025-08-08 15:04:15,636:INFO:               scipy: 1.11.4
2025-08-08 15:04:15,636:INFO:              joblib: 1.3.2
2025-08-08 15:04:15,636:INFO:             sklearn: 1.4.2
2025-08-08 15:04:15,636:INFO:                pyod: 2.0.5
2025-08-08 15:04:15,636:INFO:            imblearn: 0.13.0
2025-08-08 15:04:15,636:INFO:   category_encoders: 2.7.0
2025-08-08 15:04:15,636:INFO:            lightgbm: 4.6.0
2025-08-08 15:04:15,636:INFO:               numba: 0.61.2
2025-08-08 15:04:15,636:INFO:            requests: 2.32.4
2025-08-08 15:04:15,636:INFO:          matplotlib: 3.7.5
2025-08-08 15:04:15,636:INFO:          scikitplot: 0.3.7
2025-08-08 15:04:15,636:INFO:         yellowbrick: 1.5
2025-08-08 15:04:15,636:INFO:              plotly: 5.24.1
2025-08-08 15:04:15,637:INFO:    plotly-resampler: Not installed
2025-08-08 15:04:15,637:INFO:             kaleido: 1.0.0
2025-08-08 15:04:15,637:INFO:           schemdraw: 0.15
2025-08-08 15:04:15,637:INFO:         statsmodels: 0.14.5
2025-08-08 15:04:15,637:INFO:              sktime: 0.26.0
2025-08-08 15:04:15,637:INFO:               tbats: 1.1.3
2025-08-08 15:04:15,637:INFO:            pmdarima: 2.0.4
2025-08-08 15:04:15,637:INFO:              psutil: 7.0.0
2025-08-08 15:04:15,637:INFO:          markupsafe: 3.0.2
2025-08-08 15:04:15,637:INFO:             pickle5: Not installed
2025-08-08 15:04:15,637:INFO:         cloudpickle: 3.1.1
2025-08-08 15:04:15,637:INFO:         deprecation: 2.1.0
2025-08-08 15:04:15,637:INFO:              xxhash: 3.5.0
2025-08-08 15:04:15,637:INFO:           wurlitzer: Not installed
2025-08-08 15:04:15,637:INFO:PyCaret optional dependencies:
2025-08-08 15:04:31,324:INFO:                shap: 0.44.1
2025-08-08 15:04:31,324:INFO:           interpret: 0.6.9
2025-08-08 15:04:31,324:INFO:                umap: 0.5.7
2025-08-08 15:04:31,324:INFO:     ydata_profiling: 4.14.0
2025-08-08 15:04:31,324:INFO:  explainerdashboard: 0.4.8
2025-08-08 15:04:31,324:INFO:             autoviz: Not installed
2025-08-08 15:04:31,324:INFO:           fairlearn: 0.7.0
2025-08-08 15:04:31,324:INFO:          deepchecks: Not installed
2025-08-08 15:04:31,324:INFO:             xgboost: Not installed
2025-08-08 15:04:31,324:INFO:            catboost: 1.2.8
2025-08-08 15:04:31,324:INFO:              kmodes: 0.12.2
2025-08-08 15:04:31,325:INFO:             mlxtend: 0.23.4
2025-08-08 15:04:31,325:INFO:       statsforecast: 1.5.0
2025-08-08 15:04:31,325:INFO:        tune_sklearn: Not installed
2025-08-08 15:04:31,325:INFO:                 ray: Not installed
2025-08-08 15:04:31,325:INFO:            hyperopt: 0.2.7
2025-08-08 15:04:31,325:INFO:              optuna: 4.4.0
2025-08-08 15:04:31,325:INFO:               skopt: 0.10.2
2025-08-08 15:04:31,325:INFO:              mlflow: 3.2.0
2025-08-08 15:04:31,325:INFO:              gradio: 5.41.1
2025-08-08 15:04:31,325:INFO:             fastapi: 0.116.1
2025-08-08 15:04:31,325:INFO:             uvicorn: 0.35.0
2025-08-08 15:04:31,325:INFO:              m2cgen: 0.10.0
2025-08-08 15:04:31,325:INFO:           evidently: 0.4.40
2025-08-08 15:04:31,325:INFO:               fugue: 0.8.7
2025-08-08 15:04:31,325:INFO:           streamlit: Not installed
2025-08-08 15:04:31,325:INFO:             prophet: Not installed
2025-08-08 15:04:31,326:INFO:None
2025-08-08 15:04:31,326:INFO:Set up data.
2025-08-08 15:04:31,331:INFO:Set up folding strategy.
2025-08-08 15:04:31,332:INFO:Set up train/test split.
2025-08-08 15:04:31,337:INFO:Set up index.
2025-08-08 15:04:31,337:INFO:Assigning column types.
2025-08-08 15:04:31,341:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-08 15:04:31,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:31,494:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:31,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:31,713:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:31,714:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-08 15:04:31,780:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:31,820:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:31,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:04:31,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:31,925:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:31,926:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-08 15:04:32,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:32,032:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:32,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:32,139:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:32,145:INFO:Preparing preprocessing pipeline...
2025-08-08 15:04:32,146:INFO:Set up simple imputation.
2025-08-08 15:04:32,147:INFO:Set up column name cleaning.
2025-08-08 15:04:32,174:INFO:Finished creating preprocessing pipeline.
2025-08-08 15:04:32,184:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Benja\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body mass index (weigh...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-08-08 15:04:32,185:INFO:Creating final display dataframe.
2025-08-08 15:04:32,274:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Class variable
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5d1e
2025-08-08 15:04:32,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:32,390:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:32,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:04:32,496:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:04:32,500:INFO:setup() successfully completed in 24.83s...............
2025-08-08 15:05:20,583:INFO:Initializing compare_models()
2025-08-08 15:05:20,583:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-08 15:05:20,583:INFO:Checking exceptions
2025-08-08 15:05:20,587:INFO:Preparing display monitor
2025-08-08 15:05:20,611:INFO:Initializing Logistic Regression
2025-08-08 15:05:20,611:INFO:Total runtime is 0.0 minutes
2025-08-08 15:05:20,614:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:20,615:INFO:Initializing create_model()
2025-08-08 15:05:20,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:20,615:INFO:Checking exceptions
2025-08-08 15:05:20,615:INFO:Importing libraries
2025-08-08 15:05:20,615:INFO:Copying training dataset
2025-08-08 15:05:20,621:INFO:Defining folds
2025-08-08 15:05:20,621:INFO:Declaring metric variables
2025-08-08 15:05:20,625:INFO:Importing untrained model
2025-08-08 15:05:20,628:INFO:Logistic Regression Imported successfully
2025-08-08 15:05:20,635:INFO:Starting cross validation
2025-08-08 15:05:20,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:26,338:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,340:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,361:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,363:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,371:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,392:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,409:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,425:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,437:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:26,449:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:28,607:INFO:Calculating mean and std
2025-08-08 15:05:28,612:INFO:Creating metrics dataframe
2025-08-08 15:05:28,618:INFO:Uploading results into container
2025-08-08 15:05:28,619:INFO:Uploading model into container now
2025-08-08 15:05:28,620:INFO:_master_model_container: 1
2025-08-08 15:05:28,620:INFO:_display_container: 2
2025-08-08 15:05:28,621:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:05:28,621:INFO:create_model() successfully completed......................................
2025-08-08 15:05:28,861:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:28,861:INFO:Creating metrics dataframe
2025-08-08 15:05:28,873:INFO:Initializing K Neighbors Classifier
2025-08-08 15:05:28,873:INFO:Total runtime is 0.13770005702972413 minutes
2025-08-08 15:05:28,877:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:28,878:INFO:Initializing create_model()
2025-08-08 15:05:28,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:28,878:INFO:Checking exceptions
2025-08-08 15:05:28,878:INFO:Importing libraries
2025-08-08 15:05:28,878:INFO:Copying training dataset
2025-08-08 15:05:28,883:INFO:Defining folds
2025-08-08 15:05:28,884:INFO:Declaring metric variables
2025-08-08 15:05:28,887:INFO:Importing untrained model
2025-08-08 15:05:28,891:INFO:K Neighbors Classifier Imported successfully
2025-08-08 15:05:28,897:INFO:Starting cross validation
2025-08-08 15:05:28,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:32,681:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:32,685:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:32,690:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:32,691:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:32,691:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:32,693:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:05:34,534:INFO:Calculating mean and std
2025-08-08 15:05:34,537:INFO:Creating metrics dataframe
2025-08-08 15:05:34,540:INFO:Uploading results into container
2025-08-08 15:05:34,540:INFO:Uploading model into container now
2025-08-08 15:05:34,541:INFO:_master_model_container: 2
2025-08-08 15:05:34,541:INFO:_display_container: 2
2025-08-08 15:05:34,542:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-08 15:05:34,542:INFO:create_model() successfully completed......................................
2025-08-08 15:05:34,768:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:34,768:INFO:Creating metrics dataframe
2025-08-08 15:05:34,776:INFO:Initializing Naive Bayes
2025-08-08 15:05:34,776:INFO:Total runtime is 0.23608142534891763 minutes
2025-08-08 15:05:34,780:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:34,780:INFO:Initializing create_model()
2025-08-08 15:05:34,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:34,781:INFO:Checking exceptions
2025-08-08 15:05:34,781:INFO:Importing libraries
2025-08-08 15:05:34,781:INFO:Copying training dataset
2025-08-08 15:05:34,786:INFO:Defining folds
2025-08-08 15:05:34,786:INFO:Declaring metric variables
2025-08-08 15:05:34,789:INFO:Importing untrained model
2025-08-08 15:05:34,793:INFO:Naive Bayes Imported successfully
2025-08-08 15:05:34,799:INFO:Starting cross validation
2025-08-08 15:05:34,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:34,885:INFO:Calculating mean and std
2025-08-08 15:05:34,887:INFO:Creating metrics dataframe
2025-08-08 15:05:34,889:INFO:Uploading results into container
2025-08-08 15:05:34,889:INFO:Uploading model into container now
2025-08-08 15:05:34,890:INFO:_master_model_container: 3
2025-08-08 15:05:34,890:INFO:_display_container: 2
2025-08-08 15:05:34,890:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-08 15:05:34,890:INFO:create_model() successfully completed......................................
2025-08-08 15:05:35,051:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:35,051:INFO:Creating metrics dataframe
2025-08-08 15:05:35,059:INFO:Initializing Decision Tree Classifier
2025-08-08 15:05:35,059:INFO:Total runtime is 0.24079664548238117 minutes
2025-08-08 15:05:35,062:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:35,063:INFO:Initializing create_model()
2025-08-08 15:05:35,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:35,063:INFO:Checking exceptions
2025-08-08 15:05:35,063:INFO:Importing libraries
2025-08-08 15:05:35,063:INFO:Copying training dataset
2025-08-08 15:05:35,068:INFO:Defining folds
2025-08-08 15:05:35,069:INFO:Declaring metric variables
2025-08-08 15:05:35,072:INFO:Importing untrained model
2025-08-08 15:05:35,075:INFO:Decision Tree Classifier Imported successfully
2025-08-08 15:05:35,081:INFO:Starting cross validation
2025-08-08 15:05:35,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:35,158:INFO:Calculating mean and std
2025-08-08 15:05:35,159:INFO:Creating metrics dataframe
2025-08-08 15:05:35,161:INFO:Uploading results into container
2025-08-08 15:05:35,161:INFO:Uploading model into container now
2025-08-08 15:05:35,162:INFO:_master_model_container: 4
2025-08-08 15:05:35,162:INFO:_display_container: 2
2025-08-08 15:05:35,162:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-08-08 15:05:35,162:INFO:create_model() successfully completed......................................
2025-08-08 15:05:35,322:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:35,322:INFO:Creating metrics dataframe
2025-08-08 15:05:35,331:INFO:Initializing SVM - Linear Kernel
2025-08-08 15:05:35,331:INFO:Total runtime is 0.24533999363581338 minutes
2025-08-08 15:05:35,335:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:35,335:INFO:Initializing create_model()
2025-08-08 15:05:35,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:35,335:INFO:Checking exceptions
2025-08-08 15:05:35,335:INFO:Importing libraries
2025-08-08 15:05:35,336:INFO:Copying training dataset
2025-08-08 15:05:35,341:INFO:Defining folds
2025-08-08 15:05:35,341:INFO:Declaring metric variables
2025-08-08 15:05:35,345:INFO:Importing untrained model
2025-08-08 15:05:35,348:INFO:SVM - Linear Kernel Imported successfully
2025-08-08 15:05:35,355:INFO:Starting cross validation
2025-08-08 15:05:35,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:35,407:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:35,421:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:35,433:INFO:Calculating mean and std
2025-08-08 15:05:35,434:INFO:Creating metrics dataframe
2025-08-08 15:05:35,435:INFO:Uploading results into container
2025-08-08 15:05:35,436:INFO:Uploading model into container now
2025-08-08 15:05:35,436:INFO:_master_model_container: 5
2025-08-08 15:05:35,436:INFO:_display_container: 2
2025-08-08 15:05:35,437:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-08 15:05:35,437:INFO:create_model() successfully completed......................................
2025-08-08 15:05:35,597:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:35,597:INFO:Creating metrics dataframe
2025-08-08 15:05:35,606:INFO:Initializing Ridge Classifier
2025-08-08 15:05:35,606:INFO:Total runtime is 0.24991421302159625 minutes
2025-08-08 15:05:35,609:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:35,610:INFO:Initializing create_model()
2025-08-08 15:05:35,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:35,610:INFO:Checking exceptions
2025-08-08 15:05:35,610:INFO:Importing libraries
2025-08-08 15:05:35,610:INFO:Copying training dataset
2025-08-08 15:05:35,615:INFO:Defining folds
2025-08-08 15:05:35,615:INFO:Declaring metric variables
2025-08-08 15:05:35,619:INFO:Importing untrained model
2025-08-08 15:05:35,623:INFO:Ridge Classifier Imported successfully
2025-08-08 15:05:35,629:INFO:Starting cross validation
2025-08-08 15:05:35,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:35,705:INFO:Calculating mean and std
2025-08-08 15:05:35,706:INFO:Creating metrics dataframe
2025-08-08 15:05:35,707:INFO:Uploading results into container
2025-08-08 15:05:35,708:INFO:Uploading model into container now
2025-08-08 15:05:35,708:INFO:_master_model_container: 6
2025-08-08 15:05:35,708:INFO:_display_container: 2
2025-08-08 15:05:35,709:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-08-08 15:05:35,709:INFO:create_model() successfully completed......................................
2025-08-08 15:05:35,868:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:35,868:INFO:Creating metrics dataframe
2025-08-08 15:05:35,877:INFO:Initializing Random Forest Classifier
2025-08-08 15:05:35,877:INFO:Total runtime is 0.2544309377670288 minutes
2025-08-08 15:05:35,881:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:35,882:INFO:Initializing create_model()
2025-08-08 15:05:35,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:35,882:INFO:Checking exceptions
2025-08-08 15:05:35,882:INFO:Importing libraries
2025-08-08 15:05:35,882:INFO:Copying training dataset
2025-08-08 15:05:35,887:INFO:Defining folds
2025-08-08 15:05:35,887:INFO:Declaring metric variables
2025-08-08 15:05:35,891:INFO:Importing untrained model
2025-08-08 15:05:35,895:INFO:Random Forest Classifier Imported successfully
2025-08-08 15:05:35,901:INFO:Starting cross validation
2025-08-08 15:05:35,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:36,313:INFO:Calculating mean and std
2025-08-08 15:05:36,314:INFO:Creating metrics dataframe
2025-08-08 15:05:36,316:INFO:Uploading results into container
2025-08-08 15:05:36,317:INFO:Uploading model into container now
2025-08-08 15:05:36,317:INFO:_master_model_container: 7
2025-08-08 15:05:36,318:INFO:_display_container: 2
2025-08-08 15:05:36,318:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-08-08 15:05:36,318:INFO:create_model() successfully completed......................................
2025-08-08 15:05:36,476:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:36,476:INFO:Creating metrics dataframe
2025-08-08 15:05:36,485:INFO:Initializing Quadratic Discriminant Analysis
2025-08-08 15:05:36,485:INFO:Total runtime is 0.264565646648407 minutes
2025-08-08 15:05:36,489:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:36,489:INFO:Initializing create_model()
2025-08-08 15:05:36,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:36,489:INFO:Checking exceptions
2025-08-08 15:05:36,489:INFO:Importing libraries
2025-08-08 15:05:36,489:INFO:Copying training dataset
2025-08-08 15:05:36,494:INFO:Defining folds
2025-08-08 15:05:36,495:INFO:Declaring metric variables
2025-08-08 15:05:36,498:INFO:Importing untrained model
2025-08-08 15:05:36,502:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-08 15:05:36,509:INFO:Starting cross validation
2025-08-08 15:05:36,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:36,585:INFO:Calculating mean and std
2025-08-08 15:05:36,586:INFO:Creating metrics dataframe
2025-08-08 15:05:36,587:INFO:Uploading results into container
2025-08-08 15:05:36,588:INFO:Uploading model into container now
2025-08-08 15:05:36,588:INFO:_master_model_container: 8
2025-08-08 15:05:36,588:INFO:_display_container: 2
2025-08-08 15:05:36,589:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-08-08 15:05:36,589:INFO:create_model() successfully completed......................................
2025-08-08 15:05:36,748:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:36,748:INFO:Creating metrics dataframe
2025-08-08 15:05:36,758:INFO:Initializing Ada Boost Classifier
2025-08-08 15:05:36,758:INFO:Total runtime is 0.26911733150482176 minutes
2025-08-08 15:05:36,762:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:36,762:INFO:Initializing create_model()
2025-08-08 15:05:36,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:36,762:INFO:Checking exceptions
2025-08-08 15:05:36,763:INFO:Importing libraries
2025-08-08 15:05:36,763:INFO:Copying training dataset
2025-08-08 15:05:36,768:INFO:Defining folds
2025-08-08 15:05:36,768:INFO:Declaring metric variables
2025-08-08 15:05:36,771:INFO:Importing untrained model
2025-08-08 15:05:36,775:INFO:Ada Boost Classifier Imported successfully
2025-08-08 15:05:36,781:INFO:Starting cross validation
2025-08-08 15:05:36,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:36,807:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,809:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,811:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,812:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,816:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,820:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,821:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,823:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,830:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:36,833:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:05:37,012:INFO:Calculating mean and std
2025-08-08 15:05:37,014:INFO:Creating metrics dataframe
2025-08-08 15:05:37,016:INFO:Uploading results into container
2025-08-08 15:05:37,016:INFO:Uploading model into container now
2025-08-08 15:05:37,017:INFO:_master_model_container: 9
2025-08-08 15:05:37,017:INFO:_display_container: 2
2025-08-08 15:05:37,017:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-08-08 15:05:37,018:INFO:create_model() successfully completed......................................
2025-08-08 15:05:37,191:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:37,192:INFO:Creating metrics dataframe
2025-08-08 15:05:37,204:INFO:Initializing Gradient Boosting Classifier
2025-08-08 15:05:37,204:INFO:Total runtime is 0.2765410304069519 minutes
2025-08-08 15:05:37,208:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:37,208:INFO:Initializing create_model()
2025-08-08 15:05:37,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:37,208:INFO:Checking exceptions
2025-08-08 15:05:37,208:INFO:Importing libraries
2025-08-08 15:05:37,208:INFO:Copying training dataset
2025-08-08 15:05:37,214:INFO:Defining folds
2025-08-08 15:05:37,214:INFO:Declaring metric variables
2025-08-08 15:05:37,217:INFO:Importing untrained model
2025-08-08 15:05:37,221:INFO:Gradient Boosting Classifier Imported successfully
2025-08-08 15:05:37,228:INFO:Starting cross validation
2025-08-08 15:05:37,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:37,545:INFO:Calculating mean and std
2025-08-08 15:05:37,547:INFO:Creating metrics dataframe
2025-08-08 15:05:37,549:INFO:Uploading results into container
2025-08-08 15:05:37,550:INFO:Uploading model into container now
2025-08-08 15:05:37,550:INFO:_master_model_container: 10
2025-08-08 15:05:37,550:INFO:_display_container: 2
2025-08-08 15:05:37,551:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-08 15:05:37,551:INFO:create_model() successfully completed......................................
2025-08-08 15:05:37,724:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:37,724:INFO:Creating metrics dataframe
2025-08-08 15:05:37,734:INFO:Initializing Linear Discriminant Analysis
2025-08-08 15:05:37,734:INFO:Total runtime is 0.28538882335027055 minutes
2025-08-08 15:05:37,738:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:37,738:INFO:Initializing create_model()
2025-08-08 15:05:37,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:37,738:INFO:Checking exceptions
2025-08-08 15:05:37,738:INFO:Importing libraries
2025-08-08 15:05:37,739:INFO:Copying training dataset
2025-08-08 15:05:37,744:INFO:Defining folds
2025-08-08 15:05:37,745:INFO:Declaring metric variables
2025-08-08 15:05:37,748:INFO:Importing untrained model
2025-08-08 15:05:37,751:INFO:Linear Discriminant Analysis Imported successfully
2025-08-08 15:05:37,756:INFO:Starting cross validation
2025-08-08 15:05:37,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:37,834:INFO:Calculating mean and std
2025-08-08 15:05:37,835:INFO:Creating metrics dataframe
2025-08-08 15:05:37,836:INFO:Uploading results into container
2025-08-08 15:05:37,837:INFO:Uploading model into container now
2025-08-08 15:05:37,837:INFO:_master_model_container: 11
2025-08-08 15:05:37,837:INFO:_display_container: 2
2025-08-08 15:05:37,838:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-08 15:05:37,838:INFO:create_model() successfully completed......................................
2025-08-08 15:05:38,001:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:38,002:INFO:Creating metrics dataframe
2025-08-08 15:05:38,012:INFO:Initializing Extra Trees Classifier
2025-08-08 15:05:38,012:INFO:Total runtime is 0.2900211095809936 minutes
2025-08-08 15:05:38,016:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:38,016:INFO:Initializing create_model()
2025-08-08 15:05:38,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:38,016:INFO:Checking exceptions
2025-08-08 15:05:38,017:INFO:Importing libraries
2025-08-08 15:05:38,017:INFO:Copying training dataset
2025-08-08 15:05:38,021:INFO:Defining folds
2025-08-08 15:05:38,022:INFO:Declaring metric variables
2025-08-08 15:05:38,025:INFO:Importing untrained model
2025-08-08 15:05:38,028:INFO:Extra Trees Classifier Imported successfully
2025-08-08 15:05:38,036:INFO:Starting cross validation
2025-08-08 15:05:38,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:38,372:INFO:Calculating mean and std
2025-08-08 15:05:38,374:INFO:Creating metrics dataframe
2025-08-08 15:05:38,376:INFO:Uploading results into container
2025-08-08 15:05:38,377:INFO:Uploading model into container now
2025-08-08 15:05:38,377:INFO:_master_model_container: 12
2025-08-08 15:05:38,377:INFO:_display_container: 2
2025-08-08 15:05:38,378:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-08-08 15:05:38,378:INFO:create_model() successfully completed......................................
2025-08-08 15:05:38,536:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:38,537:INFO:Creating metrics dataframe
2025-08-08 15:05:38,547:INFO:Initializing Light Gradient Boosting Machine
2025-08-08 15:05:38,547:INFO:Total runtime is 0.298932917912801 minutes
2025-08-08 15:05:38,551:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:38,551:INFO:Initializing create_model()
2025-08-08 15:05:38,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:38,551:INFO:Checking exceptions
2025-08-08 15:05:38,552:INFO:Importing libraries
2025-08-08 15:05:38,552:INFO:Copying training dataset
2025-08-08 15:05:38,557:INFO:Defining folds
2025-08-08 15:05:38,557:INFO:Declaring metric variables
2025-08-08 15:05:38,561:INFO:Importing untrained model
2025-08-08 15:05:38,564:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 15:05:38,571:INFO:Starting cross validation
2025-08-08 15:05:38,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:38,942:INFO:Calculating mean and std
2025-08-08 15:05:38,944:INFO:Creating metrics dataframe
2025-08-08 15:05:38,946:INFO:Uploading results into container
2025-08-08 15:05:38,947:INFO:Uploading model into container now
2025-08-08 15:05:38,948:INFO:_master_model_container: 13
2025-08-08 15:05:38,948:INFO:_display_container: 2
2025-08-08 15:05:38,949:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 15:05:38,949:INFO:create_model() successfully completed......................................
2025-08-08 15:05:39,140:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:39,140:INFO:Creating metrics dataframe
2025-08-08 15:05:39,151:INFO:Initializing CatBoost Classifier
2025-08-08 15:05:39,151:INFO:Total runtime is 0.30899914503097525 minutes
2025-08-08 15:05:39,155:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:39,155:INFO:Initializing create_model()
2025-08-08 15:05:39,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:39,155:INFO:Checking exceptions
2025-08-08 15:05:39,155:INFO:Importing libraries
2025-08-08 15:05:39,155:INFO:Copying training dataset
2025-08-08 15:05:39,160:INFO:Defining folds
2025-08-08 15:05:39,160:INFO:Declaring metric variables
2025-08-08 15:05:39,164:INFO:Importing untrained model
2025-08-08 15:05:39,167:INFO:CatBoost Classifier Imported successfully
2025-08-08 15:05:39,174:INFO:Starting cross validation
2025-08-08 15:05:39,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:42,904:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-08-08 15:05:42,904:INFO:Calculating mean and std
2025-08-08 15:05:42,905:INFO:Creating metrics dataframe
2025-08-08 15:05:42,907:INFO:Uploading results into container
2025-08-08 15:05:42,908:INFO:Uploading model into container now
2025-08-08 15:05:42,908:INFO:_master_model_container: 14
2025-08-08 15:05:42,909:INFO:_display_container: 2
2025-08-08 15:05:42,909:INFO:<catboost.core.CatBoostClassifier object at 0x000001F5D5BA1BD0>
2025-08-08 15:05:42,909:INFO:create_model() successfully completed......................................
2025-08-08 15:05:43,069:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x000001F5D5BA1BD0> raised an exception or returned all 0.0, trying without fit_kwargs:
2025-08-08 15:05:43,072:WARNING:Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-08-08 15:05:43,072:INFO:Initializing create_model()
2025-08-08 15:05:43,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:43,072:INFO:Checking exceptions
2025-08-08 15:05:43,072:INFO:Importing libraries
2025-08-08 15:05:43,073:INFO:Copying training dataset
2025-08-08 15:05:43,078:INFO:Defining folds
2025-08-08 15:05:43,078:INFO:Declaring metric variables
2025-08-08 15:05:43,081:INFO:Importing untrained model
2025-08-08 15:05:43,085:INFO:CatBoost Classifier Imported successfully
2025-08-08 15:05:43,092:INFO:Starting cross validation
2025-08-08 15:05:43,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:49,692:INFO:Calculating mean and std
2025-08-08 15:05:49,693:INFO:Creating metrics dataframe
2025-08-08 15:05:49,695:INFO:Uploading results into container
2025-08-08 15:05:49,696:INFO:Uploading model into container now
2025-08-08 15:05:49,696:INFO:_master_model_container: 15
2025-08-08 15:05:49,696:INFO:_display_container: 2
2025-08-08 15:05:49,697:INFO:<catboost.core.CatBoostClassifier object at 0x000001F5CEF27A10>
2025-08-08 15:05:49,697:INFO:create_model() successfully completed......................................
2025-08-08 15:05:49,856:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:49,856:INFO:Creating metrics dataframe
2025-08-08 15:05:49,868:INFO:Initializing Dummy Classifier
2025-08-08 15:05:49,868:INFO:Total runtime is 0.48760914007822664 minutes
2025-08-08 15:05:49,872:INFO:SubProcess create_model() called ==================================
2025-08-08 15:05:49,872:INFO:Initializing create_model()
2025-08-08 15:05:49,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F589C53B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:49,872:INFO:Checking exceptions
2025-08-08 15:05:49,872:INFO:Importing libraries
2025-08-08 15:05:49,872:INFO:Copying training dataset
2025-08-08 15:05:49,878:INFO:Defining folds
2025-08-08 15:05:49,878:INFO:Declaring metric variables
2025-08-08 15:05:49,882:INFO:Importing untrained model
2025-08-08 15:05:49,885:INFO:Dummy Classifier Imported successfully
2025-08-08 15:05:49,891:INFO:Starting cross validation
2025-08-08 15:05:49,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:05:49,931:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,934:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,935:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,940:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,946:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,949:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,950:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,955:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,955:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:05:49,966:INFO:Calculating mean and std
2025-08-08 15:05:49,969:INFO:Creating metrics dataframe
2025-08-08 15:05:49,972:INFO:Uploading results into container
2025-08-08 15:05:49,972:INFO:Uploading model into container now
2025-08-08 15:05:49,973:INFO:_master_model_container: 16
2025-08-08 15:05:49,973:INFO:_display_container: 2
2025-08-08 15:05:49,973:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-08-08 15:05:49,973:INFO:create_model() successfully completed......................................
2025-08-08 15:05:50,140:INFO:SubProcess create_model() end ==================================
2025-08-08 15:05:50,140:INFO:Creating metrics dataframe
2025-08-08 15:05:50,151:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-08 15:05:50,160:INFO:Initializing create_model()
2025-08-08 15:05:50,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:05:50,160:INFO:Checking exceptions
2025-08-08 15:05:50,162:INFO:Importing libraries
2025-08-08 15:05:50,162:INFO:Copying training dataset
2025-08-08 15:05:50,167:INFO:Defining folds
2025-08-08 15:05:50,167:INFO:Declaring metric variables
2025-08-08 15:05:50,167:INFO:Importing untrained model
2025-08-08 15:05:50,167:INFO:Declaring custom model
2025-08-08 15:05:50,168:INFO:Logistic Regression Imported successfully
2025-08-08 15:05:50,169:INFO:Cross validation set to False
2025-08-08 15:05:50,169:INFO:Fitting Model
2025-08-08 15:05:50,196:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:05:50,197:INFO:create_model() successfully completed......................................
2025-08-08 15:05:50,378:INFO:_master_model_container: 16
2025-08-08 15:05:50,379:INFO:_display_container: 2
2025-08-08 15:05:50,379:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:05:50,379:INFO:compare_models() successfully completed......................................
2025-08-08 15:05:54,508:INFO:gpu_param set to False
2025-08-08 15:05:54,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:05:54,614:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:05:54,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:05:54,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:06:21,573:INFO:Initializing predict_model()
2025-08-08 15:06:21,573:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F5D62A63E0>)
2025-08-08 15:06:21,573:INFO:Checking exceptions
2025-08-08 15:06:21,573:INFO:Preloading libraries
2025-08-08 15:08:18,900:INFO:Initializing plot_model()
2025-08-08 15:08:18,900:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-08 15:08:18,900:INFO:Checking exceptions
2025-08-08 15:08:18,905:INFO:Preloading libraries
2025-08-08 15:08:18,906:INFO:Copying training dataset
2025-08-08 15:08:18,906:INFO:Plot type: confusion_matrix
2025-08-08 15:08:18,994:INFO:Fitting Model
2025-08-08 15:08:18,996:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-08-08 15:08:18,996:INFO:Scoring test/hold-out set
2025-08-08 15:08:19,159:INFO:Visual Rendered Successfully
2025-08-08 15:08:19,318:INFO:plot_model() successfully completed......................................
2025-08-08 15:08:21,879:INFO:Initializing plot_model()
2025-08-08 15:08:21,879:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-08 15:08:21,880:INFO:Checking exceptions
2025-08-08 15:08:21,885:INFO:Preloading libraries
2025-08-08 15:08:21,885:INFO:Copying training dataset
2025-08-08 15:08:21,885:INFO:Plot type: auc
2025-08-08 15:08:21,978:INFO:Fitting Model
2025-08-08 15:08:21,979:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-08-08 15:08:21,979:INFO:Scoring test/hold-out set
2025-08-08 15:08:22,199:INFO:Visual Rendered Successfully
2025-08-08 15:08:22,360:INFO:plot_model() successfully completed......................................
2025-08-08 15:08:55,371:INFO:Initializing plot_model()
2025-08-08 15:08:55,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-08 15:08:55,371:INFO:Checking exceptions
2025-08-08 15:08:55,375:INFO:Preloading libraries
2025-08-08 15:08:55,375:INFO:Copying training dataset
2025-08-08 15:08:55,375:INFO:Plot type: feature
2025-08-08 15:08:55,595:INFO:Visual Rendered Successfully
2025-08-08 15:08:55,801:INFO:plot_model() successfully completed......................................
2025-08-08 15:09:39,845:INFO:Initializing save_model()
2025-08-08 15:09:39,845:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=diabetes_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Benja\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body mass index (weigh...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-08-08 15:09:39,845:INFO:Adding model into prep_pipe
2025-08-08 15:09:39,850:INFO:diabetes_model.pkl saved in current working directory
2025-08-08 15:09:39,855:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body mass index (weight in '
                                             'kg/(height in m)^2)',
                                             'Diabetes pedigre...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-08-08 15:09:39,855:INFO:save_model() successfully completed......................................
2025-08-08 15:11:18,477:INFO:Initializing load_model()
2025-08-08 15:11:18,477:INFO:load_model(model_name=diabetes_model, platform=None, authentication=None, verbose=True)
2025-08-08 15:11:28,344:INFO:gpu_param set to False
2025-08-08 15:11:28,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:11:28,453:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:11:28,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:11:28,558:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:14:06,082:INFO:Initializing create_model()
2025-08-08 15:14:06,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:14:06,082:INFO:Checking exceptions
2025-08-08 15:14:06,098:INFO:Importing libraries
2025-08-08 15:14:06,098:INFO:Copying training dataset
2025-08-08 15:14:06,104:INFO:Defining folds
2025-08-08 15:14:06,104:INFO:Declaring metric variables
2025-08-08 15:14:06,107:INFO:Importing untrained model
2025-08-08 15:14:06,111:INFO:K Neighbors Classifier Imported successfully
2025-08-08 15:14:06,116:INFO:Starting cross validation
2025-08-08 15:14:06,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:14:12,344:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,354:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,358:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,358:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,359:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,359:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,364:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,365:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,365:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:12,365:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:14:14,442:INFO:Calculating mean and std
2025-08-08 15:14:14,445:INFO:Creating metrics dataframe
2025-08-08 15:14:14,452:INFO:Finalizing model
2025-08-08 15:14:14,474:INFO:Uploading results into container
2025-08-08 15:14:14,476:INFO:Uploading model into container now
2025-08-08 15:14:14,498:INFO:_master_model_container: 17
2025-08-08 15:14:14,498:INFO:_display_container: 4
2025-08-08 15:14:14,499:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-08 15:14:14,499:INFO:create_model() successfully completed......................................
2025-08-08 15:14:34,911:INFO:Initializing predict_model()
2025-08-08 15:14:34,913:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F5D618B2E0>)
2025-08-08 15:14:34,913:INFO:Checking exceptions
2025-08-08 15:14:34,913:INFO:Preloading libraries
2025-08-08 15:14:37,077:INFO:Initializing predict_model()
2025-08-08 15:14:37,077:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5CDB8BDD0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F5D653B6A0>)
2025-08-08 15:14:37,077:INFO:Checking exceptions
2025-08-08 15:14:37,077:INFO:Preloading libraries
2025-08-08 15:14:37,079:INFO:Set up data.
2025-08-08 15:14:37,084:INFO:Set up index.
2025-08-08 15:14:41,518:INFO:Soft dependency imported: gradio: 5.41.1
2025-08-08 15:16:46,090:INFO:Soft dependency imported: gradio: 5.41.1
2025-08-08 15:18:08,209:INFO:PyCaret ClassificationExperiment
2025-08-08 15:18:08,210:INFO:Logging name: clf-default-name
2025-08-08 15:18:08,210:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-08 15:18:08,210:INFO:version 3.3.2
2025-08-08 15:18:08,210:INFO:Initializing setup()
2025-08-08 15:18:08,210:INFO:self.USI: 3602
2025-08-08 15:18:08,210:INFO:self._variable_keys: {'seed', 'log_plots_param', 'exp_name_log', 'gpu_n_jobs_param', 'logging_param', 'X', 'html_param', 'exp_id', 'gpu_param', 'y_test', 'fold_shuffle_param', 'memory', 'fold_generator', 'fold_groups_param', 'data', 'n_jobs_param', 'X_train', '_available_plots', 'y_train', 'idx', 'target_param', 'pipeline', 'fix_imbalance', 'USI', '_ml_usecase', 'X_test', 'y', 'is_multiclass'}
2025-08-08 15:18:08,210:INFO:Checking environment
2025-08-08 15:18:08,210:INFO:python_version: 3.11.13
2025-08-08 15:18:08,210:INFO:python_build: ('main', 'Jul 11 2025 22:36:59')
2025-08-08 15:18:08,210:INFO:machine: AMD64
2025-08-08 15:18:08,210:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-08 15:18:08,219:INFO:Memory: svmem(total=17111728128, available=2969473024, percent=82.6, used=14142255104, free=2969473024)
2025-08-08 15:18:08,219:INFO:Physical Core: 8
2025-08-08 15:18:08,219:INFO:Logical Core: 16
2025-08-08 15:18:08,219:INFO:Checking libraries
2025-08-08 15:18:08,219:INFO:System:
2025-08-08 15:18:08,219:INFO:    python: 3.11.13 (main, Jul 11 2025, 22:36:59) [MSC v.1944 64 bit (AMD64)]
2025-08-08 15:18:08,219:INFO:executable: c:\Users\Benja\Documents\Projects\techcat\py311\Scripts\python.exe
2025-08-08 15:18:08,219:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-08 15:18:08,219:INFO:PyCaret required dependencies:
2025-08-08 15:18:08,219:INFO:                 pip: Not installed
2025-08-08 15:18:08,219:INFO:          setuptools: 80.9.0
2025-08-08 15:18:08,219:INFO:             pycaret: 3.3.2
2025-08-08 15:18:08,219:INFO:             IPython: 9.4.0
2025-08-08 15:18:08,219:INFO:          ipywidgets: 8.1.7
2025-08-08 15:18:08,219:INFO:                tqdm: 4.67.1
2025-08-08 15:18:08,220:INFO:               numpy: 1.26.4
2025-08-08 15:18:08,220:INFO:              pandas: 2.1.4
2025-08-08 15:18:08,220:INFO:              jinja2: 3.1.6
2025-08-08 15:18:08,220:INFO:               scipy: 1.11.4
2025-08-08 15:18:08,220:INFO:              joblib: 1.3.2
2025-08-08 15:18:08,220:INFO:             sklearn: 1.4.2
2025-08-08 15:18:08,220:INFO:                pyod: 2.0.5
2025-08-08 15:18:08,220:INFO:            imblearn: 0.13.0
2025-08-08 15:18:08,220:INFO:   category_encoders: 2.7.0
2025-08-08 15:18:08,220:INFO:            lightgbm: 4.6.0
2025-08-08 15:18:08,220:INFO:               numba: 0.61.2
2025-08-08 15:18:08,220:INFO:            requests: 2.32.4
2025-08-08 15:18:08,220:INFO:          matplotlib: 3.7.5
2025-08-08 15:18:08,220:INFO:          scikitplot: 0.3.7
2025-08-08 15:18:08,220:INFO:         yellowbrick: 1.5
2025-08-08 15:18:08,220:INFO:              plotly: 5.24.1
2025-08-08 15:18:08,220:INFO:    plotly-resampler: Not installed
2025-08-08 15:18:08,220:INFO:             kaleido: 1.0.0
2025-08-08 15:18:08,220:INFO:           schemdraw: 0.15
2025-08-08 15:18:08,220:INFO:         statsmodels: 0.14.5
2025-08-08 15:18:08,220:INFO:              sktime: 0.26.0
2025-08-08 15:18:08,221:INFO:               tbats: 1.1.3
2025-08-08 15:18:08,221:INFO:            pmdarima: 2.0.4
2025-08-08 15:18:08,221:INFO:              psutil: 7.0.0
2025-08-08 15:18:08,221:INFO:          markupsafe: 3.0.2
2025-08-08 15:18:08,221:INFO:             pickle5: Not installed
2025-08-08 15:18:08,221:INFO:         cloudpickle: 3.1.1
2025-08-08 15:18:08,221:INFO:         deprecation: 2.1.0
2025-08-08 15:18:08,221:INFO:              xxhash: 3.5.0
2025-08-08 15:18:08,221:INFO:           wurlitzer: Not installed
2025-08-08 15:18:08,221:INFO:PyCaret optional dependencies:
2025-08-08 15:18:08,221:INFO:                shap: 0.44.1
2025-08-08 15:18:08,221:INFO:           interpret: 0.6.9
2025-08-08 15:18:08,221:INFO:                umap: 0.5.7
2025-08-08 15:18:08,221:INFO:     ydata_profiling: 4.14.0
2025-08-08 15:18:08,221:INFO:  explainerdashboard: 0.4.8
2025-08-08 15:18:08,221:INFO:             autoviz: Not installed
2025-08-08 15:18:08,221:INFO:           fairlearn: 0.7.0
2025-08-08 15:18:08,221:INFO:          deepchecks: Not installed
2025-08-08 15:18:08,221:INFO:             xgboost: Not installed
2025-08-08 15:18:08,221:INFO:            catboost: 1.2.8
2025-08-08 15:18:08,221:INFO:              kmodes: 0.12.2
2025-08-08 15:18:08,222:INFO:             mlxtend: 0.23.4
2025-08-08 15:18:08,222:INFO:       statsforecast: 1.5.0
2025-08-08 15:18:08,222:INFO:        tune_sklearn: Not installed
2025-08-08 15:18:08,222:INFO:                 ray: Not installed
2025-08-08 15:18:08,222:INFO:            hyperopt: 0.2.7
2025-08-08 15:18:08,222:INFO:              optuna: 4.4.0
2025-08-08 15:18:08,222:INFO:               skopt: 0.10.2
2025-08-08 15:18:08,222:INFO:              mlflow: 3.2.0
2025-08-08 15:18:08,222:INFO:              gradio: 5.41.1
2025-08-08 15:18:08,222:INFO:             fastapi: 0.116.1
2025-08-08 15:18:08,222:INFO:             uvicorn: 0.35.0
2025-08-08 15:18:08,222:INFO:              m2cgen: 0.10.0
2025-08-08 15:18:08,222:INFO:           evidently: 0.4.40
2025-08-08 15:18:08,222:INFO:               fugue: 0.8.7
2025-08-08 15:18:08,222:INFO:           streamlit: Not installed
2025-08-08 15:18:08,222:INFO:             prophet: Not installed
2025-08-08 15:18:08,222:INFO:None
2025-08-08 15:18:08,224:INFO:Set up data.
2025-08-08 15:18:08,228:INFO:Set up folding strategy.
2025-08-08 15:18:08,228:INFO:Set up train/test split.
2025-08-08 15:18:08,234:INFO:Set up index.
2025-08-08 15:18:08,234:INFO:Assigning column types.
2025-08-08 15:18:08,237:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-08 15:18:08,300:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,301:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,341:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,416:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,457:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,458:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-08 15:18:08,534:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,576:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-08 15:18:08,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,687:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,688:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-08 15:18:08,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,798:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:08,903:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:08,905:INFO:Preparing preprocessing pipeline...
2025-08-08 15:18:08,906:INFO:Set up label encoding.
2025-08-08 15:18:08,906:INFO:Set up simple imputation.
2025-08-08 15:18:08,928:INFO:Finished creating preprocessing pipeline.
2025-08-08 15:18:08,933:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Benja\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-08 15:18:08,933:INFO:Creating final display dataframe.
2025-08-08 15:18:09,008:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                             species  
2                                          Multiclass  
3   Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...  
4                                            (150, 5)  
5                                            (150, 5)  
6                                            (105, 5)  
7                                             (45, 5)  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               3602  
2025-08-08 15:18:09,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:09,148:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:09,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:18:09,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:18:09,261:INFO:setup() successfully completed in 1.06s...............
2025-08-08 15:18:09,425:INFO:Initializing compare_models()
2025-08-08 15:18:09,425:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-08 15:18:09,425:INFO:Checking exceptions
2025-08-08 15:18:09,428:INFO:Preparing display monitor
2025-08-08 15:18:09,452:INFO:Initializing Logistic Regression
2025-08-08 15:18:09,452:INFO:Total runtime is 1.4821688334147136e-06 minutes
2025-08-08 15:18:09,455:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:09,455:INFO:Initializing create_model()
2025-08-08 15:18:09,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:09,455:INFO:Checking exceptions
2025-08-08 15:18:09,455:INFO:Importing libraries
2025-08-08 15:18:09,456:INFO:Copying training dataset
2025-08-08 15:18:09,459:INFO:Defining folds
2025-08-08 15:18:09,460:INFO:Declaring metric variables
2025-08-08 15:18:09,462:INFO:Importing untrained model
2025-08-08 15:18:09,465:INFO:Logistic Regression Imported successfully
2025-08-08 15:18:09,472:INFO:Starting cross validation
2025-08-08 15:18:09,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:09,548:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:09,553:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,554:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:09,557:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:09,559:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,559:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,561:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:09,562:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,564:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,564:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,565:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,565:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,568:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,570:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,570:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:09,575:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:12,906:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:12,908:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:12,913:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:12,918:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:12,923:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:12,926:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-08 15:18:14,443:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,445:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,446:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,449:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,449:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,451:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,452:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,452:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,454:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,455:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,456:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,458:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,458:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,461:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,461:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,464:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,467:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,468:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:14,470:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,472:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,474:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,475:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,478:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,479:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,496:INFO:Calculating mean and std
2025-08-08 15:18:14,498:INFO:Creating metrics dataframe
2025-08-08 15:18:14,501:INFO:Uploading results into container
2025-08-08 15:18:14,502:INFO:Uploading model into container now
2025-08-08 15:18:14,502:INFO:_master_model_container: 1
2025-08-08 15:18:14,502:INFO:_display_container: 2
2025-08-08 15:18:14,503:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:18:14,503:INFO:create_model() successfully completed......................................
2025-08-08 15:18:14,747:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:14,747:INFO:Creating metrics dataframe
2025-08-08 15:18:14,754:INFO:Initializing K Neighbors Classifier
2025-08-08 15:18:14,754:INFO:Total runtime is 0.08837554454803467 minutes
2025-08-08 15:18:14,757:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:14,758:INFO:Initializing create_model()
2025-08-08 15:18:14,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:14,758:INFO:Checking exceptions
2025-08-08 15:18:14,758:INFO:Importing libraries
2025-08-08 15:18:14,758:INFO:Copying training dataset
2025-08-08 15:18:14,763:INFO:Defining folds
2025-08-08 15:18:14,763:INFO:Declaring metric variables
2025-08-08 15:18:14,767:INFO:Importing untrained model
2025-08-08 15:18:14,770:INFO:K Neighbors Classifier Imported successfully
2025-08-08 15:18:14,775:INFO:Starting cross validation
2025-08-08 15:18:14,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:14,861:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,862:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,863:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,865:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,865:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,866:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,868:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,869:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,869:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,870:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,870:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,872:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,872:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,874:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,875:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,876:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,877:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,877:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,877:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,878:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,879:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,881:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,882:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,882:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,883:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,884:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,887:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:14,902:INFO:Calculating mean and std
2025-08-08 15:18:14,903:INFO:Creating metrics dataframe
2025-08-08 15:18:14,905:INFO:Uploading results into container
2025-08-08 15:18:14,906:INFO:Uploading model into container now
2025-08-08 15:18:14,906:INFO:_master_model_container: 2
2025-08-08 15:18:14,906:INFO:_display_container: 2
2025-08-08 15:18:14,907:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-08 15:18:14,907:INFO:create_model() successfully completed......................................
2025-08-08 15:18:15,085:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:15,086:INFO:Creating metrics dataframe
2025-08-08 15:18:15,098:INFO:Initializing Naive Bayes
2025-08-08 15:18:15,098:INFO:Total runtime is 0.09411168495814005 minutes
2025-08-08 15:18:15,102:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:15,102:INFO:Initializing create_model()
2025-08-08 15:18:15,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:15,103:INFO:Checking exceptions
2025-08-08 15:18:15,103:INFO:Importing libraries
2025-08-08 15:18:15,103:INFO:Copying training dataset
2025-08-08 15:18:15,107:INFO:Defining folds
2025-08-08 15:18:15,107:INFO:Declaring metric variables
2025-08-08 15:18:15,113:INFO:Importing untrained model
2025-08-08 15:18:15,116:INFO:Naive Bayes Imported successfully
2025-08-08 15:18:15,122:INFO:Starting cross validation
2025-08-08 15:18:15,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:15,169:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,172:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,173:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,174:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,174:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,174:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,175:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,176:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,177:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,177:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,178:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,179:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,180:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,180:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,181:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,182:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,182:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,184:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,184:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,185:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,187:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,187:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,189:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,190:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,190:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,193:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,196:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,210:INFO:Calculating mean and std
2025-08-08 15:18:15,211:INFO:Creating metrics dataframe
2025-08-08 15:18:15,213:INFO:Uploading results into container
2025-08-08 15:18:15,214:INFO:Uploading model into container now
2025-08-08 15:18:15,214:INFO:_master_model_container: 3
2025-08-08 15:18:15,214:INFO:_display_container: 2
2025-08-08 15:18:15,215:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-08 15:18:15,215:INFO:create_model() successfully completed......................................
2025-08-08 15:18:15,388:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:15,388:INFO:Creating metrics dataframe
2025-08-08 15:18:15,397:INFO:Initializing Decision Tree Classifier
2025-08-08 15:18:15,397:INFO:Total runtime is 0.09908897876739502 minutes
2025-08-08 15:18:15,400:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:15,400:INFO:Initializing create_model()
2025-08-08 15:18:15,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:15,401:INFO:Checking exceptions
2025-08-08 15:18:15,401:INFO:Importing libraries
2025-08-08 15:18:15,401:INFO:Copying training dataset
2025-08-08 15:18:15,405:INFO:Defining folds
2025-08-08 15:18:15,405:INFO:Declaring metric variables
2025-08-08 15:18:15,409:INFO:Importing untrained model
2025-08-08 15:18:15,413:INFO:Decision Tree Classifier Imported successfully
2025-08-08 15:18:15,418:INFO:Starting cross validation
2025-08-08 15:18:15,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:15,456:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,457:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,459:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,460:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,460:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,462:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,463:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,463:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,463:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,464:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,465:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,466:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,467:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,468:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,468:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,469:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,469:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,472:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,472:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,472:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,472:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,474:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,475:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,478:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,479:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,482:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,482:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,484:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,485:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,493:INFO:Calculating mean and std
2025-08-08 15:18:15,493:INFO:Creating metrics dataframe
2025-08-08 15:18:15,495:INFO:Uploading results into container
2025-08-08 15:18:15,495:INFO:Uploading model into container now
2025-08-08 15:18:15,496:INFO:_master_model_container: 4
2025-08-08 15:18:15,496:INFO:_display_container: 2
2025-08-08 15:18:15,496:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-08-08 15:18:15,497:INFO:create_model() successfully completed......................................
2025-08-08 15:18:15,678:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:15,679:INFO:Creating metrics dataframe
2025-08-08 15:18:15,688:INFO:Initializing SVM - Linear Kernel
2025-08-08 15:18:15,688:INFO:Total runtime is 0.10393072366714477 minutes
2025-08-08 15:18:15,692:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:15,692:INFO:Initializing create_model()
2025-08-08 15:18:15,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:15,693:INFO:Checking exceptions
2025-08-08 15:18:15,693:INFO:Importing libraries
2025-08-08 15:18:15,693:INFO:Copying training dataset
2025-08-08 15:18:15,697:INFO:Defining folds
2025-08-08 15:18:15,697:INFO:Declaring metric variables
2025-08-08 15:18:15,701:INFO:Importing untrained model
2025-08-08 15:18:15,705:INFO:SVM - Linear Kernel Imported successfully
2025-08-08 15:18:15,711:INFO:Starting cross validation
2025-08-08 15:18:15,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:15,776:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,778:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,779:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,779:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,779:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,780:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,781:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,781:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,782:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,783:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,783:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,784:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,784:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,785:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,785:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,785:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,785:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,786:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,786:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,787:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,787:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,787:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,788:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,788:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,789:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,789:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,789:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,790:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,791:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,792:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,792:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,793:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,794:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,794:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,796:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,796:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,797:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:15,797:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,798:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,799:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,800:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,801:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,801:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,802:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,802:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:15,804:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:15,818:INFO:Calculating mean and std
2025-08-08 15:18:15,819:INFO:Creating metrics dataframe
2025-08-08 15:18:15,821:INFO:Uploading results into container
2025-08-08 15:18:15,822:INFO:Uploading model into container now
2025-08-08 15:18:15,822:INFO:_master_model_container: 5
2025-08-08 15:18:15,822:INFO:_display_container: 2
2025-08-08 15:18:15,823:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-08 15:18:15,823:INFO:create_model() successfully completed......................................
2025-08-08 15:18:15,997:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:15,998:INFO:Creating metrics dataframe
2025-08-08 15:18:16,006:INFO:Initializing Ridge Classifier
2025-08-08 15:18:16,006:INFO:Total runtime is 0.10924396514892577 minutes
2025-08-08 15:18:16,010:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:16,010:INFO:Initializing create_model()
2025-08-08 15:18:16,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:16,010:INFO:Checking exceptions
2025-08-08 15:18:16,010:INFO:Importing libraries
2025-08-08 15:18:16,011:INFO:Copying training dataset
2025-08-08 15:18:16,015:INFO:Defining folds
2025-08-08 15:18:16,015:INFO:Declaring metric variables
2025-08-08 15:18:16,019:INFO:Importing untrained model
2025-08-08 15:18:16,022:INFO:Ridge Classifier Imported successfully
2025-08-08 15:18:16,028:INFO:Starting cross validation
2025-08-08 15:18:16,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:16,073:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,074:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,076:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,076:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,077:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,077:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,077:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,078:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,078:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,079:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,079:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,079:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,080:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,080:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,081:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,081:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,081:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,082:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,082:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,083:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,083:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,083:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,084:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,085:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,085:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,086:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,087:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,088:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,088:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,088:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,089:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,092:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,095:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,102:INFO:Calculating mean and std
2025-08-08 15:18:16,103:INFO:Creating metrics dataframe
2025-08-08 15:18:16,105:INFO:Uploading results into container
2025-08-08 15:18:16,105:INFO:Uploading model into container now
2025-08-08 15:18:16,106:INFO:_master_model_container: 6
2025-08-08 15:18:16,106:INFO:_display_container: 2
2025-08-08 15:18:16,106:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-08-08 15:18:16,106:INFO:create_model() successfully completed......................................
2025-08-08 15:18:16,287:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:16,287:INFO:Creating metrics dataframe
2025-08-08 15:18:16,296:INFO:Initializing Random Forest Classifier
2025-08-08 15:18:16,297:INFO:Total runtime is 0.11409531434377033 minutes
2025-08-08 15:18:16,300:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:16,300:INFO:Initializing create_model()
2025-08-08 15:18:16,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:16,300:INFO:Checking exceptions
2025-08-08 15:18:16,301:INFO:Importing libraries
2025-08-08 15:18:16,302:INFO:Copying training dataset
2025-08-08 15:18:16,306:INFO:Defining folds
2025-08-08 15:18:16,306:INFO:Declaring metric variables
2025-08-08 15:18:16,309:INFO:Importing untrained model
2025-08-08 15:18:16,313:INFO:Random Forest Classifier Imported successfully
2025-08-08 15:18:16,318:INFO:Starting cross validation
2025-08-08 15:18:16,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:16,617:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,620:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,624:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,625:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,625:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,628:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,628:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,629:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,629:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,629:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,633:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,634:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,634:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,634:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,634:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,635:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,636:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,637:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,637:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,637:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,638:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,641:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,641:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,644:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,659:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,662:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,663:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,665:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,665:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,668:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,674:INFO:Calculating mean and std
2025-08-08 15:18:16,676:INFO:Creating metrics dataframe
2025-08-08 15:18:16,677:INFO:Uploading results into container
2025-08-08 15:18:16,678:INFO:Uploading model into container now
2025-08-08 15:18:16,678:INFO:_master_model_container: 7
2025-08-08 15:18:16,679:INFO:_display_container: 2
2025-08-08 15:18:16,679:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-08-08 15:18:16,679:INFO:create_model() successfully completed......................................
2025-08-08 15:18:16,855:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:16,855:INFO:Creating metrics dataframe
2025-08-08 15:18:16,865:INFO:Initializing Quadratic Discriminant Analysis
2025-08-08 15:18:16,865:INFO:Total runtime is 0.12354855140050251 minutes
2025-08-08 15:18:16,869:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:16,869:INFO:Initializing create_model()
2025-08-08 15:18:16,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:16,869:INFO:Checking exceptions
2025-08-08 15:18:16,869:INFO:Importing libraries
2025-08-08 15:18:16,869:INFO:Copying training dataset
2025-08-08 15:18:16,874:INFO:Defining folds
2025-08-08 15:18:16,874:INFO:Declaring metric variables
2025-08-08 15:18:16,878:INFO:Importing untrained model
2025-08-08 15:18:16,881:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-08 15:18:16,887:INFO:Starting cross validation
2025-08-08 15:18:16,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:16,924:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,925:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,926:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,928:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,929:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,930:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,931:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,932:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,932:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,933:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,933:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,933:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,935:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,935:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,935:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,936:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,936:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,937:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,937:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,938:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,938:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,938:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,938:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,940:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,940:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,945:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,945:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,948:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:16,950:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,953:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,956:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:16,962:INFO:Calculating mean and std
2025-08-08 15:18:16,963:INFO:Creating metrics dataframe
2025-08-08 15:18:16,965:INFO:Uploading results into container
2025-08-08 15:18:16,965:INFO:Uploading model into container now
2025-08-08 15:18:16,966:INFO:_master_model_container: 8
2025-08-08 15:18:16,966:INFO:_display_container: 2
2025-08-08 15:18:16,966:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-08-08 15:18:16,966:INFO:create_model() successfully completed......................................
2025-08-08 15:18:17,146:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:17,146:INFO:Creating metrics dataframe
2025-08-08 15:18:17,156:INFO:Initializing Ada Boost Classifier
2025-08-08 15:18:17,156:INFO:Total runtime is 0.1283972382545471 minutes
2025-08-08 15:18:17,160:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:17,160:INFO:Initializing create_model()
2025-08-08 15:18:17,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:17,160:INFO:Checking exceptions
2025-08-08 15:18:17,161:INFO:Importing libraries
2025-08-08 15:18:17,161:INFO:Copying training dataset
2025-08-08 15:18:17,164:INFO:Defining folds
2025-08-08 15:18:17,164:INFO:Declaring metric variables
2025-08-08 15:18:17,167:INFO:Importing untrained model
2025-08-08 15:18:17,171:INFO:Ada Boost Classifier Imported successfully
2025-08-08 15:18:17,176:INFO:Starting cross validation
2025-08-08 15:18:17,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:17,200:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,203:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,207:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,208:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,209:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,212:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,213:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,216:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,217:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,220:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-08 15:18:17,311:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,313:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,317:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,318:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,321:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,321:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,322:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,322:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,323:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,325:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,326:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,326:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,327:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,328:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,329:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,329:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,330:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,331:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,334:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,334:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,337:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,339:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,341:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,341:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,342:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,343:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,343:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,345:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,345:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,346:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,348:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,349:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,349:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,350:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,350:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,352:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,353:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,355:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,356:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,358:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,365:INFO:Calculating mean and std
2025-08-08 15:18:17,367:INFO:Creating metrics dataframe
2025-08-08 15:18:17,369:INFO:Uploading results into container
2025-08-08 15:18:17,369:INFO:Uploading model into container now
2025-08-08 15:18:17,370:INFO:_master_model_container: 9
2025-08-08 15:18:17,370:INFO:_display_container: 2
2025-08-08 15:18:17,370:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-08-08 15:18:17,370:INFO:create_model() successfully completed......................................
2025-08-08 15:18:17,550:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:17,550:INFO:Creating metrics dataframe
2025-08-08 15:18:17,560:INFO:Initializing Gradient Boosting Classifier
2025-08-08 15:18:17,561:INFO:Total runtime is 0.1351422071456909 minutes
2025-08-08 15:18:17,564:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:17,564:INFO:Initializing create_model()
2025-08-08 15:18:17,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:17,564:INFO:Checking exceptions
2025-08-08 15:18:17,565:INFO:Importing libraries
2025-08-08 15:18:17,565:INFO:Copying training dataset
2025-08-08 15:18:17,569:INFO:Defining folds
2025-08-08 15:18:17,569:INFO:Declaring metric variables
2025-08-08 15:18:17,573:INFO:Importing untrained model
2025-08-08 15:18:17,576:INFO:Gradient Boosting Classifier Imported successfully
2025-08-08 15:18:17,582:INFO:Starting cross validation
2025-08-08 15:18:17,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:17,931:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,933:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,936:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,944:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,945:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,947:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,947:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,950:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,950:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,953:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,962:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,964:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,968:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,970:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,972:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,972:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,974:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,977:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,977:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,978:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,981:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,984:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,986:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:17,987:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,990:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:17,993:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,000:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,003:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,005:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,008:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,008:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,010:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,013:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,016:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,020:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,022:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,025:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,028:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,044:INFO:Calculating mean and std
2025-08-08 15:18:18,046:INFO:Creating metrics dataframe
2025-08-08 15:18:18,048:INFO:Uploading results into container
2025-08-08 15:18:18,048:INFO:Uploading model into container now
2025-08-08 15:18:18,049:INFO:_master_model_container: 10
2025-08-08 15:18:18,049:INFO:_display_container: 2
2025-08-08 15:18:18,049:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-08 15:18:18,049:INFO:create_model() successfully completed......................................
2025-08-08 15:18:18,231:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:18,232:INFO:Creating metrics dataframe
2025-08-08 15:18:18,244:INFO:Initializing Linear Discriminant Analysis
2025-08-08 15:18:18,245:INFO:Total runtime is 0.14654668966929116 minutes
2025-08-08 15:18:18,248:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:18,248:INFO:Initializing create_model()
2025-08-08 15:18:18,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:18,249:INFO:Checking exceptions
2025-08-08 15:18:18,249:INFO:Importing libraries
2025-08-08 15:18:18,249:INFO:Copying training dataset
2025-08-08 15:18:18,253:INFO:Defining folds
2025-08-08 15:18:18,253:INFO:Declaring metric variables
2025-08-08 15:18:18,257:INFO:Importing untrained model
2025-08-08 15:18:18,260:INFO:Linear Discriminant Analysis Imported successfully
2025-08-08 15:18:18,266:INFO:Starting cross validation
2025-08-08 15:18:18,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:18,307:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,309:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,310:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,310:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,310:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,310:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,311:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,311:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,312:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,312:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,312:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,313:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,313:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,314:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,314:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,314:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,314:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,315:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,315:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,315:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,316:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,317:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,317:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,317:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,317:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,318:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,318:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,318:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,319:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,320:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,321:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,321:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,322:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,323:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-08-08 15:18:18,323:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,324:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,325:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,328:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,331:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,338:INFO:Calculating mean and std
2025-08-08 15:18:18,339:INFO:Creating metrics dataframe
2025-08-08 15:18:18,340:INFO:Uploading results into container
2025-08-08 15:18:18,341:INFO:Uploading model into container now
2025-08-08 15:18:18,341:INFO:_master_model_container: 11
2025-08-08 15:18:18,341:INFO:_display_container: 2
2025-08-08 15:18:18,342:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-08 15:18:18,342:INFO:create_model() successfully completed......................................
2025-08-08 15:18:18,515:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:18,516:INFO:Creating metrics dataframe
2025-08-08 15:18:18,529:INFO:Initializing Extra Trees Classifier
2025-08-08 15:18:18,530:INFO:Total runtime is 0.15129249890645344 minutes
2025-08-08 15:18:18,533:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:18,534:INFO:Initializing create_model()
2025-08-08 15:18:18,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:18,535:INFO:Checking exceptions
2025-08-08 15:18:18,535:INFO:Importing libraries
2025-08-08 15:18:18,535:INFO:Copying training dataset
2025-08-08 15:18:18,544:INFO:Defining folds
2025-08-08 15:18:18,544:INFO:Declaring metric variables
2025-08-08 15:18:18,548:INFO:Importing untrained model
2025-08-08 15:18:18,551:INFO:Extra Trees Classifier Imported successfully
2025-08-08 15:18:18,556:INFO:Starting cross validation
2025-08-08 15:18:18,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:18,813:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,815:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,815:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,817:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,818:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,818:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,819:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,822:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,822:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,822:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,823:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,823:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,823:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,826:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,826:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,828:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,831:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,832:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,834:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,834:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,837:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,837:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,839:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,848:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,850:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,851:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,853:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,854:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,856:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:18,871:INFO:Calculating mean and std
2025-08-08 15:18:18,873:INFO:Creating metrics dataframe
2025-08-08 15:18:18,875:INFO:Uploading results into container
2025-08-08 15:18:18,876:INFO:Uploading model into container now
2025-08-08 15:18:18,876:INFO:_master_model_container: 12
2025-08-08 15:18:18,876:INFO:_display_container: 2
2025-08-08 15:18:18,877:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-08-08 15:18:18,877:INFO:create_model() successfully completed......................................
2025-08-08 15:18:19,060:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:19,060:INFO:Creating metrics dataframe
2025-08-08 15:18:19,070:INFO:Initializing Light Gradient Boosting Machine
2025-08-08 15:18:19,071:INFO:Total runtime is 0.16031939188639321 minutes
2025-08-08 15:18:19,074:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:19,075:INFO:Initializing create_model()
2025-08-08 15:18:19,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:19,075:INFO:Checking exceptions
2025-08-08 15:18:19,075:INFO:Importing libraries
2025-08-08 15:18:19,075:INFO:Copying training dataset
2025-08-08 15:18:19,079:INFO:Defining folds
2025-08-08 15:18:19,079:INFO:Declaring metric variables
2025-08-08 15:18:19,083:INFO:Importing untrained model
2025-08-08 15:18:19,086:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 15:18:19,093:INFO:Starting cross validation
2025-08-08 15:18:19,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:19,281:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,285:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,289:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,304:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,308:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,312:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,320:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,324:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,328:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,328:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,332:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,332:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,333:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,336:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,337:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,338:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,341:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,341:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,352:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,356:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,358:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,360:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,361:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,364:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,365:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,369:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,372:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,376:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,380:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,384:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:19,399:INFO:Calculating mean and std
2025-08-08 15:18:19,401:INFO:Creating metrics dataframe
2025-08-08 15:18:19,403:INFO:Uploading results into container
2025-08-08 15:18:19,404:INFO:Uploading model into container now
2025-08-08 15:18:19,404:INFO:_master_model_container: 13
2025-08-08 15:18:19,405:INFO:_display_container: 2
2025-08-08 15:18:19,406:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-08 15:18:19,406:INFO:create_model() successfully completed......................................
2025-08-08 15:18:19,607:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:19,607:INFO:Creating metrics dataframe
2025-08-08 15:18:19,618:INFO:Initializing CatBoost Classifier
2025-08-08 15:18:19,618:INFO:Total runtime is 0.16943601767222086 minutes
2025-08-08 15:18:19,621:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:19,621:INFO:Initializing create_model()
2025-08-08 15:18:19,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:19,622:INFO:Checking exceptions
2025-08-08 15:18:19,622:INFO:Importing libraries
2025-08-08 15:18:19,622:INFO:Copying training dataset
2025-08-08 15:18:19,627:INFO:Defining folds
2025-08-08 15:18:19,627:INFO:Declaring metric variables
2025-08-08 15:18:19,631:INFO:Importing untrained model
2025-08-08 15:18:19,634:INFO:CatBoost Classifier Imported successfully
2025-08-08 15:18:19,640:INFO:Starting cross validation
2025-08-08 15:18:19,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:22,065:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,070:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,070:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,075:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,079:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,082:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,087:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,091:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,120:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,124:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,128:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,460:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,465:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,469:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,526:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,530:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,534:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,554:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,558:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,561:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,564:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,568:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,572:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,611:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,614:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,618:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,653:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,656:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,660:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,671:INFO:Calculating mean and std
2025-08-08 15:18:22,672:INFO:Creating metrics dataframe
2025-08-08 15:18:22,674:INFO:Uploading results into container
2025-08-08 15:18:22,675:INFO:Uploading model into container now
2025-08-08 15:18:22,675:INFO:_master_model_container: 14
2025-08-08 15:18:22,676:INFO:_display_container: 2
2025-08-08 15:18:22,676:INFO:<catboost.core.CatBoostClassifier object at 0x000001F5DA5297D0>
2025-08-08 15:18:22,676:INFO:create_model() successfully completed......................................
2025-08-08 15:18:22,851:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:22,851:INFO:Creating metrics dataframe
2025-08-08 15:18:22,864:INFO:Initializing Dummy Classifier
2025-08-08 15:18:22,864:INFO:Total runtime is 0.22354540427525837 minutes
2025-08-08 15:18:22,867:INFO:SubProcess create_model() called ==================================
2025-08-08 15:18:22,868:INFO:Initializing create_model()
2025-08-08 15:18:22,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA80F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:22,868:INFO:Checking exceptions
2025-08-08 15:18:22,868:INFO:Importing libraries
2025-08-08 15:18:22,868:INFO:Copying training dataset
2025-08-08 15:18:22,873:INFO:Defining folds
2025-08-08 15:18:22,873:INFO:Declaring metric variables
2025-08-08 15:18:22,877:INFO:Importing untrained model
2025-08-08 15:18:22,880:INFO:Dummy Classifier Imported successfully
2025-08-08 15:18:22,885:INFO:Starting cross validation
2025-08-08 15:18:22,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:18:22,917:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,922:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,923:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,924:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,924:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,925:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,926:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,926:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,927:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,928:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,928:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,928:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,929:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,929:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,930:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,931:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,931:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,932:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,932:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,933:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,934:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,937:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,939:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,940:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,940:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,942:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,943:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,944:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,944:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,944:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,945:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,946:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,946:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,947:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,948:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-08 15:18:22,950:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-08-08 15:18:22,959:INFO:Calculating mean and std
2025-08-08 15:18:22,960:INFO:Creating metrics dataframe
2025-08-08 15:18:22,961:INFO:Uploading results into container
2025-08-08 15:18:22,962:INFO:Uploading model into container now
2025-08-08 15:18:22,962:INFO:_master_model_container: 15
2025-08-08 15:18:22,962:INFO:_display_container: 2
2025-08-08 15:18:22,963:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-08-08 15:18:22,963:INFO:create_model() successfully completed......................................
2025-08-08 15:18:23,139:INFO:SubProcess create_model() end ==================================
2025-08-08 15:18:23,139:INFO:Creating metrics dataframe
2025-08-08 15:18:23,153:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-08 15:18:23,162:INFO:Initializing create_model()
2025-08-08 15:18:23,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F5DA1E1690>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:18:23,162:INFO:Checking exceptions
2025-08-08 15:18:23,164:INFO:Importing libraries
2025-08-08 15:18:23,164:INFO:Copying training dataset
2025-08-08 15:18:23,168:INFO:Defining folds
2025-08-08 15:18:23,168:INFO:Declaring metric variables
2025-08-08 15:18:23,168:INFO:Importing untrained model
2025-08-08 15:18:23,168:INFO:Declaring custom model
2025-08-08 15:18:23,169:INFO:Logistic Regression Imported successfully
2025-08-08 15:18:23,169:INFO:Cross validation set to False
2025-08-08 15:18:23,170:INFO:Fitting Model
2025-08-08 15:18:23,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:18:23,191:INFO:create_model() successfully completed......................................
2025-08-08 15:18:23,392:INFO:_master_model_container: 15
2025-08-08 15:18:23,392:INFO:_display_container: 2
2025-08-08 15:18:23,393:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-08 15:18:23,393:INFO:compare_models() successfully completed......................................
2025-08-08 15:21:01,292:INFO:PyCaret RegressionExperiment
2025-08-08 15:21:01,292:INFO:Logging name: reg-default-name
2025-08-08 15:21:01,294:INFO:ML Usecase: MLUsecase.REGRESSION
2025-08-08 15:21:01,294:INFO:version 3.3.2
2025-08-08 15:21:01,294:INFO:Initializing setup()
2025-08-08 15:21:01,294:INFO:self.USI: d9a2
2025-08-08 15:21:01,294:INFO:self._variable_keys: {'seed', 'log_plots_param', 'exp_name_log', 'gpu_n_jobs_param', 'logging_param', 'X', 'html_param', 'exp_id', 'gpu_param', 'y_test', 'fold_shuffle_param', 'memory', 'fold_generator', 'fold_groups_param', 'data', 'n_jobs_param', 'X_train', '_available_plots', 'y_train', 'idx', 'target_param', 'transform_target_param', 'pipeline', 'USI', '_ml_usecase', 'X_test', 'y'}
2025-08-08 15:21:01,294:INFO:Checking environment
2025-08-08 15:21:01,294:INFO:python_version: 3.11.13
2025-08-08 15:21:01,294:INFO:python_build: ('main', 'Jul 11 2025 22:36:59')
2025-08-08 15:21:01,294:INFO:machine: AMD64
2025-08-08 15:21:01,294:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-08 15:21:01,303:INFO:Memory: svmem(total=17111728128, available=1815138304, percent=89.4, used=15296589824, free=1815138304)
2025-08-08 15:21:01,303:INFO:Physical Core: 8
2025-08-08 15:21:01,303:INFO:Logical Core: 16
2025-08-08 15:21:01,303:INFO:Checking libraries
2025-08-08 15:21:01,303:INFO:System:
2025-08-08 15:21:01,303:INFO:    python: 3.11.13 (main, Jul 11 2025, 22:36:59) [MSC v.1944 64 bit (AMD64)]
2025-08-08 15:21:01,303:INFO:executable: c:\Users\Benja\Documents\Projects\techcat\py311\Scripts\python.exe
2025-08-08 15:21:01,303:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-08 15:21:01,303:INFO:PyCaret required dependencies:
2025-08-08 15:21:01,303:INFO:                 pip: Not installed
2025-08-08 15:21:01,304:INFO:          setuptools: 80.9.0
2025-08-08 15:21:01,304:INFO:             pycaret: 3.3.2
2025-08-08 15:21:01,304:INFO:             IPython: 9.4.0
2025-08-08 15:21:01,304:INFO:          ipywidgets: 8.1.7
2025-08-08 15:21:01,304:INFO:                tqdm: 4.67.1
2025-08-08 15:21:01,304:INFO:               numpy: 1.26.4
2025-08-08 15:21:01,304:INFO:              pandas: 2.1.4
2025-08-08 15:21:01,304:INFO:              jinja2: 3.1.6
2025-08-08 15:21:01,304:INFO:               scipy: 1.11.4
2025-08-08 15:21:01,304:INFO:              joblib: 1.3.2
2025-08-08 15:21:01,304:INFO:             sklearn: 1.4.2
2025-08-08 15:21:01,304:INFO:                pyod: 2.0.5
2025-08-08 15:21:01,304:INFO:            imblearn: 0.13.0
2025-08-08 15:21:01,304:INFO:   category_encoders: 2.7.0
2025-08-08 15:21:01,304:INFO:            lightgbm: 4.6.0
2025-08-08 15:21:01,304:INFO:               numba: 0.61.2
2025-08-08 15:21:01,304:INFO:            requests: 2.32.4
2025-08-08 15:21:01,305:INFO:          matplotlib: 3.7.5
2025-08-08 15:21:01,305:INFO:          scikitplot: 0.3.7
2025-08-08 15:21:01,305:INFO:         yellowbrick: 1.5
2025-08-08 15:21:01,305:INFO:              plotly: 5.24.1
2025-08-08 15:21:01,305:INFO:    plotly-resampler: Not installed
2025-08-08 15:21:01,305:INFO:             kaleido: 1.0.0
2025-08-08 15:21:01,305:INFO:           schemdraw: 0.15
2025-08-08 15:21:01,305:INFO:         statsmodels: 0.14.5
2025-08-08 15:21:01,305:INFO:              sktime: 0.26.0
2025-08-08 15:21:01,305:INFO:               tbats: 1.1.3
2025-08-08 15:21:01,305:INFO:            pmdarima: 2.0.4
2025-08-08 15:21:01,305:INFO:              psutil: 7.0.0
2025-08-08 15:21:01,305:INFO:          markupsafe: 3.0.2
2025-08-08 15:21:01,305:INFO:             pickle5: Not installed
2025-08-08 15:21:01,305:INFO:         cloudpickle: 3.1.1
2025-08-08 15:21:01,305:INFO:         deprecation: 2.1.0
2025-08-08 15:21:01,305:INFO:              xxhash: 3.5.0
2025-08-08 15:21:01,305:INFO:           wurlitzer: Not installed
2025-08-08 15:21:01,306:INFO:PyCaret optional dependencies:
2025-08-08 15:21:01,306:INFO:                shap: 0.44.1
2025-08-08 15:21:01,306:INFO:           interpret: 0.6.9
2025-08-08 15:21:01,306:INFO:                umap: 0.5.7
2025-08-08 15:21:01,306:INFO:     ydata_profiling: 4.14.0
2025-08-08 15:21:01,306:INFO:  explainerdashboard: 0.4.8
2025-08-08 15:21:01,306:INFO:             autoviz: Not installed
2025-08-08 15:21:01,306:INFO:           fairlearn: 0.7.0
2025-08-08 15:21:01,306:INFO:          deepchecks: Not installed
2025-08-08 15:21:01,306:INFO:             xgboost: Not installed
2025-08-08 15:21:01,306:INFO:            catboost: 1.2.8
2025-08-08 15:21:01,306:INFO:              kmodes: 0.12.2
2025-08-08 15:21:01,306:INFO:             mlxtend: 0.23.4
2025-08-08 15:21:01,306:INFO:       statsforecast: 1.5.0
2025-08-08 15:21:01,306:INFO:        tune_sklearn: Not installed
2025-08-08 15:21:01,306:INFO:                 ray: Not installed
2025-08-08 15:21:01,306:INFO:            hyperopt: 0.2.7
2025-08-08 15:21:01,307:INFO:              optuna: 4.4.0
2025-08-08 15:21:01,307:INFO:               skopt: 0.10.2
2025-08-08 15:21:01,307:INFO:              mlflow: 3.2.0
2025-08-08 15:21:01,307:INFO:              gradio: 5.41.1
2025-08-08 15:21:01,307:INFO:             fastapi: 0.116.1
2025-08-08 15:21:01,307:INFO:             uvicorn: 0.35.0
2025-08-08 15:21:01,307:INFO:              m2cgen: 0.10.0
2025-08-08 15:21:01,307:INFO:           evidently: 0.4.40
2025-08-08 15:21:01,307:INFO:               fugue: 0.8.7
2025-08-08 15:21:01,307:INFO:           streamlit: Not installed
2025-08-08 15:21:01,307:INFO:             prophet: Not installed
2025-08-08 15:21:01,307:INFO:None
2025-08-08 15:21:01,307:INFO:Set up data.
2025-08-08 15:21:01,312:INFO:Set up folding strategy.
2025-08-08 15:21:01,312:INFO:Set up train/test split.
2025-08-08 15:21:01,316:INFO:Set up index.
2025-08-08 15:21:01,316:INFO:Assigning column types.
2025-08-08 15:21:01,319:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-08 15:21:01,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,326:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:01,505:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:01,507:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,514:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,600:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,664:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:01,666:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:01,667:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-08-08 15:21:01,675:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,681:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:01,861:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:01,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,876:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:01,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,041:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,041:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-08-08 15:21:02,054:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,134:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,199:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,216:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,377:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,378:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-08-08 15:21:02,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,556:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,721:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,721:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-08 15:21:02,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:02,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:02,881:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:02,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-08-08 15:21:03,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:03,054:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:03,055:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-08-08 15:21:03,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:03,216:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:03,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:03,391:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:03,393:INFO:Preparing preprocessing pipeline...
2025-08-08 15:21:03,393:INFO:Set up simple imputation.
2025-08-08 15:21:03,396:INFO:Set up encoding of ordinal features.
2025-08-08 15:21:03,398:INFO:Set up encoding of categorical features.
2025-08-08 15:21:03,487:INFO:Finished creating preprocessing pipeline.
2025-08-08 15:21:03,512:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Benja\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-08-08 15:21:03,512:INFO:Creating final display dataframe.
2025-08-08 15:21:03,735:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Numeric features                 3
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d9a2
2025-08-08 15:21:03,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:03,911:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:04,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-08 15:21:04,080:INFO:Soft dependency imported: catboost: 1.2.8
2025-08-08 15:21:04,081:INFO:setup() successfully completed in 2.79s...............
2025-08-08 15:21:13,908:INFO:Initializing compare_models()
2025-08-08 15:21:13,908:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-08-08 15:21:13,908:INFO:Checking exceptions
2025-08-08 15:21:13,910:INFO:Preparing display monitor
2025-08-08 15:21:13,930:INFO:Initializing Linear Regression
2025-08-08 15:21:13,930:INFO:Total runtime is 0.0 minutes
2025-08-08 15:21:13,934:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:13,935:INFO:Initializing create_model()
2025-08-08 15:21:13,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:13,935:INFO:Checking exceptions
2025-08-08 15:21:13,935:INFO:Importing libraries
2025-08-08 15:21:13,935:INFO:Copying training dataset
2025-08-08 15:21:13,941:INFO:Defining folds
2025-08-08 15:21:13,941:INFO:Declaring metric variables
2025-08-08 15:21:13,944:INFO:Importing untrained model
2025-08-08 15:21:13,947:INFO:Linear Regression Imported successfully
2025-08-08 15:21:13,953:INFO:Starting cross validation
2025-08-08 15:21:13,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:14,127:INFO:Calculating mean and std
2025-08-08 15:21:14,128:INFO:Creating metrics dataframe
2025-08-08 15:21:14,129:INFO:Uploading results into container
2025-08-08 15:21:14,130:INFO:Uploading model into container now
2025-08-08 15:21:14,131:INFO:_master_model_container: 1
2025-08-08 15:21:14,131:INFO:_display_container: 2
2025-08-08 15:21:14,131:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-08-08 15:21:14,131:INFO:create_model() successfully completed......................................
2025-08-08 15:21:14,310:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:14,311:INFO:Creating metrics dataframe
2025-08-08 15:21:14,318:INFO:Initializing Lasso Regression
2025-08-08 15:21:14,318:INFO:Total runtime is 0.006458580493927002 minutes
2025-08-08 15:21:14,321:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:14,321:INFO:Initializing create_model()
2025-08-08 15:21:14,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:14,322:INFO:Checking exceptions
2025-08-08 15:21:14,322:INFO:Importing libraries
2025-08-08 15:21:14,322:INFO:Copying training dataset
2025-08-08 15:21:14,326:INFO:Defining folds
2025-08-08 15:21:14,326:INFO:Declaring metric variables
2025-08-08 15:21:14,329:INFO:Importing untrained model
2025-08-08 15:21:14,332:INFO:Lasso Regression Imported successfully
2025-08-08 15:21:14,338:INFO:Starting cross validation
2025-08-08 15:21:14,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:14,513:INFO:Calculating mean and std
2025-08-08 15:21:14,514:INFO:Creating metrics dataframe
2025-08-08 15:21:14,515:INFO:Uploading results into container
2025-08-08 15:21:14,516:INFO:Uploading model into container now
2025-08-08 15:21:14,516:INFO:_master_model_container: 2
2025-08-08 15:21:14,516:INFO:_display_container: 2
2025-08-08 15:21:14,517:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-08-08 15:21:14,517:INFO:create_model() successfully completed......................................
2025-08-08 15:21:14,696:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:14,696:INFO:Creating metrics dataframe
2025-08-08 15:21:14,704:INFO:Initializing Ridge Regression
2025-08-08 15:21:14,705:INFO:Total runtime is 0.012906690438588459 minutes
2025-08-08 15:21:14,708:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:14,709:INFO:Initializing create_model()
2025-08-08 15:21:14,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:14,709:INFO:Checking exceptions
2025-08-08 15:21:14,709:INFO:Importing libraries
2025-08-08 15:21:14,709:INFO:Copying training dataset
2025-08-08 15:21:14,713:INFO:Defining folds
2025-08-08 15:21:14,714:INFO:Declaring metric variables
2025-08-08 15:21:14,717:INFO:Importing untrained model
2025-08-08 15:21:14,721:INFO:Ridge Regression Imported successfully
2025-08-08 15:21:14,728:INFO:Starting cross validation
2025-08-08 15:21:14,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:14,896:INFO:Calculating mean and std
2025-08-08 15:21:14,897:INFO:Creating metrics dataframe
2025-08-08 15:21:14,899:INFO:Uploading results into container
2025-08-08 15:21:14,899:INFO:Uploading model into container now
2025-08-08 15:21:14,899:INFO:_master_model_container: 3
2025-08-08 15:21:14,900:INFO:_display_container: 2
2025-08-08 15:21:14,900:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-08-08 15:21:14,900:INFO:create_model() successfully completed......................................
2025-08-08 15:21:15,076:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:15,076:INFO:Creating metrics dataframe
2025-08-08 15:21:15,084:INFO:Initializing Elastic Net
2025-08-08 15:21:15,084:INFO:Total runtime is 0.01922076940536499 minutes
2025-08-08 15:21:15,088:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:15,088:INFO:Initializing create_model()
2025-08-08 15:21:15,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:15,088:INFO:Checking exceptions
2025-08-08 15:21:15,089:INFO:Importing libraries
2025-08-08 15:21:15,089:INFO:Copying training dataset
2025-08-08 15:21:15,093:INFO:Defining folds
2025-08-08 15:21:15,093:INFO:Declaring metric variables
2025-08-08 15:21:15,097:INFO:Importing untrained model
2025-08-08 15:21:15,100:INFO:Elastic Net Imported successfully
2025-08-08 15:21:15,106:INFO:Starting cross validation
2025-08-08 15:21:15,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:15,281:INFO:Calculating mean and std
2025-08-08 15:21:15,282:INFO:Creating metrics dataframe
2025-08-08 15:21:15,284:INFO:Uploading results into container
2025-08-08 15:21:15,285:INFO:Uploading model into container now
2025-08-08 15:21:15,285:INFO:_master_model_container: 4
2025-08-08 15:21:15,286:INFO:_display_container: 2
2025-08-08 15:21:15,286:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-08-08 15:21:15,286:INFO:create_model() successfully completed......................................
2025-08-08 15:21:15,462:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:15,462:INFO:Creating metrics dataframe
2025-08-08 15:21:15,471:INFO:Initializing Least Angle Regression
2025-08-08 15:21:15,471:INFO:Total runtime is 0.025677887598673503 minutes
2025-08-08 15:21:15,474:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:15,474:INFO:Initializing create_model()
2025-08-08 15:21:15,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:15,474:INFO:Checking exceptions
2025-08-08 15:21:15,475:INFO:Importing libraries
2025-08-08 15:21:15,475:INFO:Copying training dataset
2025-08-08 15:21:15,479:INFO:Defining folds
2025-08-08 15:21:15,479:INFO:Declaring metric variables
2025-08-08 15:21:15,483:INFO:Importing untrained model
2025-08-08 15:21:15,486:INFO:Least Angle Regression Imported successfully
2025-08-08 15:21:15,492:INFO:Starting cross validation
2025-08-08 15:21:15,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:15,665:INFO:Calculating mean and std
2025-08-08 15:21:15,667:INFO:Creating metrics dataframe
2025-08-08 15:21:15,669:INFO:Uploading results into container
2025-08-08 15:21:15,669:INFO:Uploading model into container now
2025-08-08 15:21:15,670:INFO:_master_model_container: 5
2025-08-08 15:21:15,670:INFO:_display_container: 2
2025-08-08 15:21:15,670:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-08-08 15:21:15,670:INFO:create_model() successfully completed......................................
2025-08-08 15:21:15,855:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:15,856:INFO:Creating metrics dataframe
2025-08-08 15:21:15,865:INFO:Initializing Lasso Least Angle Regression
2025-08-08 15:21:15,865:INFO:Total runtime is 0.03224639892578125 minutes
2025-08-08 15:21:15,868:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:15,869:INFO:Initializing create_model()
2025-08-08 15:21:15,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:15,869:INFO:Checking exceptions
2025-08-08 15:21:15,869:INFO:Importing libraries
2025-08-08 15:21:15,869:INFO:Copying training dataset
2025-08-08 15:21:15,874:INFO:Defining folds
2025-08-08 15:21:15,874:INFO:Declaring metric variables
2025-08-08 15:21:15,877:INFO:Importing untrained model
2025-08-08 15:21:15,880:INFO:Lasso Least Angle Regression Imported successfully
2025-08-08 15:21:15,886:INFO:Starting cross validation
2025-08-08 15:21:15,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:16,065:INFO:Calculating mean and std
2025-08-08 15:21:16,067:INFO:Creating metrics dataframe
2025-08-08 15:21:16,069:INFO:Uploading results into container
2025-08-08 15:21:16,070:INFO:Uploading model into container now
2025-08-08 15:21:16,070:INFO:_master_model_container: 6
2025-08-08 15:21:16,070:INFO:_display_container: 2
2025-08-08 15:21:16,071:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-08-08 15:21:16,071:INFO:create_model() successfully completed......................................
2025-08-08 15:21:16,247:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:16,247:INFO:Creating metrics dataframe
2025-08-08 15:21:16,256:INFO:Initializing Orthogonal Matching Pursuit
2025-08-08 15:21:16,256:INFO:Total runtime is 0.038755619525909425 minutes
2025-08-08 15:21:16,259:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:16,259:INFO:Initializing create_model()
2025-08-08 15:21:16,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:16,259:INFO:Checking exceptions
2025-08-08 15:21:16,260:INFO:Importing libraries
2025-08-08 15:21:16,260:INFO:Copying training dataset
2025-08-08 15:21:16,264:INFO:Defining folds
2025-08-08 15:21:16,264:INFO:Declaring metric variables
2025-08-08 15:21:16,267:INFO:Importing untrained model
2025-08-08 15:21:16,271:INFO:Orthogonal Matching Pursuit Imported successfully
2025-08-08 15:21:16,277:INFO:Starting cross validation
2025-08-08 15:21:16,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:16,446:INFO:Calculating mean and std
2025-08-08 15:21:16,447:INFO:Creating metrics dataframe
2025-08-08 15:21:16,449:INFO:Uploading results into container
2025-08-08 15:21:16,450:INFO:Uploading model into container now
2025-08-08 15:21:16,450:INFO:_master_model_container: 7
2025-08-08 15:21:16,450:INFO:_display_container: 2
2025-08-08 15:21:16,451:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-08-08 15:21:16,451:INFO:create_model() successfully completed......................................
2025-08-08 15:21:16,626:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:16,627:INFO:Creating metrics dataframe
2025-08-08 15:21:16,636:INFO:Initializing Bayesian Ridge
2025-08-08 15:21:16,636:INFO:Total runtime is 0.045092050234476724 minutes
2025-08-08 15:21:16,640:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:16,641:INFO:Initializing create_model()
2025-08-08 15:21:16,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:16,641:INFO:Checking exceptions
2025-08-08 15:21:16,641:INFO:Importing libraries
2025-08-08 15:21:16,641:INFO:Copying training dataset
2025-08-08 15:21:16,646:INFO:Defining folds
2025-08-08 15:21:16,646:INFO:Declaring metric variables
2025-08-08 15:21:16,650:INFO:Importing untrained model
2025-08-08 15:21:16,653:INFO:Bayesian Ridge Imported successfully
2025-08-08 15:21:16,659:INFO:Starting cross validation
2025-08-08 15:21:16,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:16,829:INFO:Calculating mean and std
2025-08-08 15:21:16,830:INFO:Creating metrics dataframe
2025-08-08 15:21:16,832:INFO:Uploading results into container
2025-08-08 15:21:16,833:INFO:Uploading model into container now
2025-08-08 15:21:16,833:INFO:_master_model_container: 8
2025-08-08 15:21:16,833:INFO:_display_container: 2
2025-08-08 15:21:16,834:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-08-08 15:21:16,834:INFO:create_model() successfully completed......................................
2025-08-08 15:21:17,009:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:17,010:INFO:Creating metrics dataframe
2025-08-08 15:21:17,026:INFO:Initializing Passive Aggressive Regressor
2025-08-08 15:21:17,027:INFO:Total runtime is 0.05161252021789551 minutes
2025-08-08 15:21:17,030:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:17,030:INFO:Initializing create_model()
2025-08-08 15:21:17,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:17,031:INFO:Checking exceptions
2025-08-08 15:21:17,031:INFO:Importing libraries
2025-08-08 15:21:17,031:INFO:Copying training dataset
2025-08-08 15:21:17,035:INFO:Defining folds
2025-08-08 15:21:17,036:INFO:Declaring metric variables
2025-08-08 15:21:17,040:INFO:Importing untrained model
2025-08-08 15:21:17,043:INFO:Passive Aggressive Regressor Imported successfully
2025-08-08 15:21:17,049:INFO:Starting cross validation
2025-08-08 15:21:17,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:17,228:INFO:Calculating mean and std
2025-08-08 15:21:17,230:INFO:Creating metrics dataframe
2025-08-08 15:21:17,233:INFO:Uploading results into container
2025-08-08 15:21:17,233:INFO:Uploading model into container now
2025-08-08 15:21:17,234:INFO:_master_model_container: 9
2025-08-08 15:21:17,234:INFO:_display_container: 2
2025-08-08 15:21:17,234:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-08 15:21:17,234:INFO:create_model() successfully completed......................................
2025-08-08 15:21:17,410:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:17,411:INFO:Creating metrics dataframe
2025-08-08 15:21:17,420:INFO:Initializing Huber Regressor
2025-08-08 15:21:17,420:INFO:Total runtime is 0.058155834674835205 minutes
2025-08-08 15:21:17,423:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:17,424:INFO:Initializing create_model()
2025-08-08 15:21:17,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:17,424:INFO:Checking exceptions
2025-08-08 15:21:17,424:INFO:Importing libraries
2025-08-08 15:21:17,424:INFO:Copying training dataset
2025-08-08 15:21:17,428:INFO:Defining folds
2025-08-08 15:21:17,429:INFO:Declaring metric variables
2025-08-08 15:21:17,432:INFO:Importing untrained model
2025-08-08 15:21:17,436:INFO:Huber Regressor Imported successfully
2025-08-08 15:21:17,442:INFO:Starting cross validation
2025-08-08 15:21:17,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:17,556:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,565:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,568:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,572:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,580:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,580:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,593:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,597:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,609:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,630:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-08-08 15:21:17,658:INFO:Calculating mean and std
2025-08-08 15:21:17,660:INFO:Creating metrics dataframe
2025-08-08 15:21:17,663:INFO:Uploading results into container
2025-08-08 15:21:17,664:INFO:Uploading model into container now
2025-08-08 15:21:17,664:INFO:_master_model_container: 10
2025-08-08 15:21:17,665:INFO:_display_container: 2
2025-08-08 15:21:17,665:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-08-08 15:21:17,665:INFO:create_model() successfully completed......................................
2025-08-08 15:21:17,841:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:17,841:INFO:Creating metrics dataframe
2025-08-08 15:21:17,850:INFO:Initializing K Neighbors Regressor
2025-08-08 15:21:17,851:INFO:Total runtime is 0.06533885399500529 minutes
2025-08-08 15:21:17,854:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:17,855:INFO:Initializing create_model()
2025-08-08 15:21:17,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:17,855:INFO:Checking exceptions
2025-08-08 15:21:17,855:INFO:Importing libraries
2025-08-08 15:21:17,855:INFO:Copying training dataset
2025-08-08 15:21:17,859:INFO:Defining folds
2025-08-08 15:21:17,859:INFO:Declaring metric variables
2025-08-08 15:21:17,862:INFO:Importing untrained model
2025-08-08 15:21:17,866:INFO:K Neighbors Regressor Imported successfully
2025-08-08 15:21:17,872:INFO:Starting cross validation
2025-08-08 15:21:17,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:18,067:INFO:Calculating mean and std
2025-08-08 15:21:18,068:INFO:Creating metrics dataframe
2025-08-08 15:21:18,071:INFO:Uploading results into container
2025-08-08 15:21:18,071:INFO:Uploading model into container now
2025-08-08 15:21:18,072:INFO:_master_model_container: 11
2025-08-08 15:21:18,072:INFO:_display_container: 2
2025-08-08 15:21:18,072:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-08-08 15:21:18,072:INFO:create_model() successfully completed......................................
2025-08-08 15:21:18,249:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:18,249:INFO:Creating metrics dataframe
2025-08-08 15:21:18,260:INFO:Initializing Decision Tree Regressor
2025-08-08 15:21:18,260:INFO:Total runtime is 0.07216120560963948 minutes
2025-08-08 15:21:18,268:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:18,268:INFO:Initializing create_model()
2025-08-08 15:21:18,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:18,269:INFO:Checking exceptions
2025-08-08 15:21:18,269:INFO:Importing libraries
2025-08-08 15:21:18,269:INFO:Copying training dataset
2025-08-08 15:21:18,276:INFO:Defining folds
2025-08-08 15:21:18,276:INFO:Declaring metric variables
2025-08-08 15:21:18,280:INFO:Importing untrained model
2025-08-08 15:21:18,284:INFO:Decision Tree Regressor Imported successfully
2025-08-08 15:21:18,291:INFO:Starting cross validation
2025-08-08 15:21:18,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:18,466:INFO:Calculating mean and std
2025-08-08 15:21:18,468:INFO:Creating metrics dataframe
2025-08-08 15:21:18,470:INFO:Uploading results into container
2025-08-08 15:21:18,471:INFO:Uploading model into container now
2025-08-08 15:21:18,471:INFO:_master_model_container: 12
2025-08-08 15:21:18,472:INFO:_display_container: 2
2025-08-08 15:21:18,473:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-08-08 15:21:18,473:INFO:create_model() successfully completed......................................
2025-08-08 15:21:18,663:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:18,663:INFO:Creating metrics dataframe
2025-08-08 15:21:18,675:INFO:Initializing Random Forest Regressor
2025-08-08 15:21:18,675:INFO:Total runtime is 0.07906991640726725 minutes
2025-08-08 15:21:18,678:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:18,679:INFO:Initializing create_model()
2025-08-08 15:21:18,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:18,679:INFO:Checking exceptions
2025-08-08 15:21:18,679:INFO:Importing libraries
2025-08-08 15:21:18,679:INFO:Copying training dataset
2025-08-08 15:21:18,685:INFO:Defining folds
2025-08-08 15:21:18,685:INFO:Declaring metric variables
2025-08-08 15:21:18,689:INFO:Importing untrained model
2025-08-08 15:21:18,692:INFO:Random Forest Regressor Imported successfully
2025-08-08 15:21:18,699:INFO:Starting cross validation
2025-08-08 15:21:18,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:19,294:INFO:Calculating mean and std
2025-08-08 15:21:19,296:INFO:Creating metrics dataframe
2025-08-08 15:21:19,298:INFO:Uploading results into container
2025-08-08 15:21:19,298:INFO:Uploading model into container now
2025-08-08 15:21:19,299:INFO:_master_model_container: 13
2025-08-08 15:21:19,299:INFO:_display_container: 2
2025-08-08 15:21:19,300:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-08-08 15:21:19,300:INFO:create_model() successfully completed......................................
2025-08-08 15:21:19,477:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:19,478:INFO:Creating metrics dataframe
2025-08-08 15:21:19,494:INFO:Initializing Extra Trees Regressor
2025-08-08 15:21:19,494:INFO:Total runtime is 0.09272392590840657 minutes
2025-08-08 15:21:19,497:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:19,498:INFO:Initializing create_model()
2025-08-08 15:21:19,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:19,498:INFO:Checking exceptions
2025-08-08 15:21:19,498:INFO:Importing libraries
2025-08-08 15:21:19,499:INFO:Copying training dataset
2025-08-08 15:21:19,503:INFO:Defining folds
2025-08-08 15:21:19,503:INFO:Declaring metric variables
2025-08-08 15:21:19,507:INFO:Importing untrained model
2025-08-08 15:21:19,510:INFO:Extra Trees Regressor Imported successfully
2025-08-08 15:21:19,516:INFO:Starting cross validation
2025-08-08 15:21:19,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:19,991:INFO:Calculating mean and std
2025-08-08 15:21:19,993:INFO:Creating metrics dataframe
2025-08-08 15:21:19,995:INFO:Uploading results into container
2025-08-08 15:21:19,996:INFO:Uploading model into container now
2025-08-08 15:21:19,996:INFO:_master_model_container: 14
2025-08-08 15:21:19,996:INFO:_display_container: 2
2025-08-08 15:21:19,997:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-08-08 15:21:19,997:INFO:create_model() successfully completed......................................
2025-08-08 15:21:20,174:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:20,174:INFO:Creating metrics dataframe
2025-08-08 15:21:20,185:INFO:Initializing AdaBoost Regressor
2025-08-08 15:21:20,185:INFO:Total runtime is 0.10424743096033731 minutes
2025-08-08 15:21:20,189:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:20,190:INFO:Initializing create_model()
2025-08-08 15:21:20,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:20,190:INFO:Checking exceptions
2025-08-08 15:21:20,190:INFO:Importing libraries
2025-08-08 15:21:20,190:INFO:Copying training dataset
2025-08-08 15:21:20,197:INFO:Defining folds
2025-08-08 15:21:20,197:INFO:Declaring metric variables
2025-08-08 15:21:20,199:INFO:Importing untrained model
2025-08-08 15:21:20,203:INFO:AdaBoost Regressor Imported successfully
2025-08-08 15:21:20,209:INFO:Starting cross validation
2025-08-08 15:21:20,211:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:20,421:INFO:Calculating mean and std
2025-08-08 15:21:20,423:INFO:Creating metrics dataframe
2025-08-08 15:21:20,424:INFO:Uploading results into container
2025-08-08 15:21:20,424:INFO:Uploading model into container now
2025-08-08 15:21:20,425:INFO:_master_model_container: 15
2025-08-08 15:21:20,425:INFO:_display_container: 2
2025-08-08 15:21:20,425:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-08-08 15:21:20,426:INFO:create_model() successfully completed......................................
2025-08-08 15:21:20,602:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:20,602:INFO:Creating metrics dataframe
2025-08-08 15:21:20,616:INFO:Initializing Gradient Boosting Regressor
2025-08-08 15:21:20,616:INFO:Total runtime is 0.11141785780588785 minutes
2025-08-08 15:21:20,620:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:20,621:INFO:Initializing create_model()
2025-08-08 15:21:20,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:20,621:INFO:Checking exceptions
2025-08-08 15:21:20,621:INFO:Importing libraries
2025-08-08 15:21:20,621:INFO:Copying training dataset
2025-08-08 15:21:20,626:INFO:Defining folds
2025-08-08 15:21:20,626:INFO:Declaring metric variables
2025-08-08 15:21:20,630:INFO:Importing untrained model
2025-08-08 15:21:20,633:INFO:Gradient Boosting Regressor Imported successfully
2025-08-08 15:21:20,639:INFO:Starting cross validation
2025-08-08 15:21:20,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:20,942:INFO:Calculating mean and std
2025-08-08 15:21:20,943:INFO:Creating metrics dataframe
2025-08-08 15:21:20,946:INFO:Uploading results into container
2025-08-08 15:21:20,946:INFO:Uploading model into container now
2025-08-08 15:21:20,947:INFO:_master_model_container: 16
2025-08-08 15:21:20,947:INFO:_display_container: 2
2025-08-08 15:21:20,948:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-08 15:21:20,948:INFO:create_model() successfully completed......................................
2025-08-08 15:21:21,126:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:21,126:INFO:Creating metrics dataframe
2025-08-08 15:21:21,138:INFO:Initializing Light Gradient Boosting Machine
2025-08-08 15:21:21,138:INFO:Total runtime is 0.12012737194697061 minutes
2025-08-08 15:21:21,142:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:21,142:INFO:Initializing create_model()
2025-08-08 15:21:21,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:21,142:INFO:Checking exceptions
2025-08-08 15:21:21,142:INFO:Importing libraries
2025-08-08 15:21:21,143:INFO:Copying training dataset
2025-08-08 15:21:21,147:INFO:Defining folds
2025-08-08 15:21:21,147:INFO:Declaring metric variables
2025-08-08 15:21:21,151:INFO:Importing untrained model
2025-08-08 15:21:21,155:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-08 15:21:21,161:INFO:Starting cross validation
2025-08-08 15:21:21,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:21,733:INFO:Calculating mean and std
2025-08-08 15:21:21,735:INFO:Creating metrics dataframe
2025-08-08 15:21:21,737:INFO:Uploading results into container
2025-08-08 15:21:21,738:INFO:Uploading model into container now
2025-08-08 15:21:21,738:INFO:_master_model_container: 17
2025-08-08 15:21:21,738:INFO:_display_container: 2
2025-08-08 15:21:21,740:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-08-08 15:21:21,740:INFO:create_model() successfully completed......................................
2025-08-08 15:21:21,943:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:21,943:INFO:Creating metrics dataframe
2025-08-08 15:21:21,956:INFO:Initializing CatBoost Regressor
2025-08-08 15:21:21,956:INFO:Total runtime is 0.133754293123881 minutes
2025-08-08 15:21:21,960:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:21,960:INFO:Initializing create_model()
2025-08-08 15:21:21,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:21,961:INFO:Checking exceptions
2025-08-08 15:21:21,961:INFO:Importing libraries
2025-08-08 15:21:21,961:INFO:Copying training dataset
2025-08-08 15:21:21,966:INFO:Defining folds
2025-08-08 15:21:21,966:INFO:Declaring metric variables
2025-08-08 15:21:21,970:INFO:Importing untrained model
2025-08-08 15:21:21,974:INFO:CatBoost Regressor Imported successfully
2025-08-08 15:21:21,981:INFO:Starting cross validation
2025-08-08 15:21:21,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:25,319:INFO:Calculating mean and std
2025-08-08 15:21:25,321:INFO:Creating metrics dataframe
2025-08-08 15:21:25,323:INFO:Uploading results into container
2025-08-08 15:21:25,323:INFO:Uploading model into container now
2025-08-08 15:21:25,324:INFO:_master_model_container: 18
2025-08-08 15:21:25,324:INFO:_display_container: 2
2025-08-08 15:21:25,324:INFO:<catboost.core.CatBoostRegressor object at 0x000001F5DA37FC10>
2025-08-08 15:21:25,324:INFO:create_model() successfully completed......................................
2025-08-08 15:21:25,501:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:25,501:INFO:Creating metrics dataframe
2025-08-08 15:21:25,512:INFO:Initializing Dummy Regressor
2025-08-08 15:21:25,512:INFO:Total runtime is 0.1930259148279826 minutes
2025-08-08 15:21:25,516:INFO:SubProcess create_model() called ==================================
2025-08-08 15:21:25,517:INFO:Initializing create_model()
2025-08-08 15:21:25,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F5DA38F0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:25,517:INFO:Checking exceptions
2025-08-08 15:21:25,517:INFO:Importing libraries
2025-08-08 15:21:25,517:INFO:Copying training dataset
2025-08-08 15:21:25,522:INFO:Defining folds
2025-08-08 15:21:25,522:INFO:Declaring metric variables
2025-08-08 15:21:25,525:INFO:Importing untrained model
2025-08-08 15:21:25,529:INFO:Dummy Regressor Imported successfully
2025-08-08 15:21:25,535:INFO:Starting cross validation
2025-08-08 15:21:25,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-08 15:21:25,710:INFO:Calculating mean and std
2025-08-08 15:21:25,711:INFO:Creating metrics dataframe
2025-08-08 15:21:25,713:INFO:Uploading results into container
2025-08-08 15:21:25,714:INFO:Uploading model into container now
2025-08-08 15:21:25,714:INFO:_master_model_container: 19
2025-08-08 15:21:25,714:INFO:_display_container: 2
2025-08-08 15:21:25,715:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-08-08 15:21:25,715:INFO:create_model() successfully completed......................................
2025-08-08 15:21:25,892:INFO:SubProcess create_model() end ==================================
2025-08-08 15:21:25,893:INFO:Creating metrics dataframe
2025-08-08 15:21:25,907:WARNING:c:\Users\Benja\Documents\Projects\techcat\py311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-08 15:21:25,915:INFO:Initializing create_model()
2025-08-08 15:21:25,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F5D121FAD0>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-08 15:21:25,916:INFO:Checking exceptions
2025-08-08 15:21:25,917:INFO:Importing libraries
2025-08-08 15:21:25,918:INFO:Copying training dataset
2025-08-08 15:21:25,922:INFO:Defining folds
2025-08-08 15:21:25,922:INFO:Declaring metric variables
2025-08-08 15:21:25,922:INFO:Importing untrained model
2025-08-08 15:21:25,922:INFO:Declaring custom model
2025-08-08 15:21:25,923:INFO:Gradient Boosting Regressor Imported successfully
2025-08-08 15:21:25,924:INFO:Cross validation set to False
2025-08-08 15:21:25,924:INFO:Fitting Model
2025-08-08 15:21:26,076:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-08 15:21:26,076:INFO:create_model() successfully completed......................................
2025-08-08 15:21:26,281:INFO:_master_model_container: 19
2025-08-08 15:21:26,281:INFO:_display_container: 2
2025-08-08 15:21:26,282:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-08 15:21:26,282:INFO:compare_models() successfully completed......................................
2025-08-08 15:26:18,782:INFO:PyCaret ClusteringExperiment
2025-08-08 15:26:18,782:INFO:Logging name: cluster-default-name
2025-08-08 15:26:18,782:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-08-08 15:26:18,782:INFO:version 3.3.2
2025-08-08 15:26:18,782:INFO:Initializing setup()
2025-08-08 15:26:18,783:INFO:self.USI: 70bc
2025-08-08 15:26:18,783:INFO:self._variable_keys: {'seed', 'log_plots_param', 'exp_name_log', 'gpu_n_jobs_param', 'logging_param', 'X', 'html_param', 'exp_id', 'gpu_param', 'memory', 'data', 'n_jobs_param', '_available_plots', 'idx', 'pipeline', 'USI', '_ml_usecase'}
2025-08-08 15:26:18,783:INFO:Checking environment
2025-08-08 15:26:18,783:INFO:python_version: 3.11.13
2025-08-08 15:26:18,783:INFO:python_build: ('main', 'Jul 11 2025 22:36:59')
2025-08-08 15:26:18,783:INFO:machine: AMD64
2025-08-08 15:26:18,783:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-08 15:26:18,792:INFO:Memory: svmem(total=17111728128, available=1635766272, percent=90.4, used=15475961856, free=1635766272)
2025-08-08 15:26:18,792:INFO:Physical Core: 8
2025-08-08 15:26:18,792:INFO:Logical Core: 16
2025-08-08 15:26:18,792:INFO:Checking libraries
2025-08-08 15:26:18,792:INFO:System:
2025-08-08 15:26:18,792:INFO:    python: 3.11.13 (main, Jul 11 2025, 22:36:59) [MSC v.1944 64 bit (AMD64)]
2025-08-08 15:26:18,793:INFO:executable: c:\Users\Benja\Documents\Projects\techcat\py311\Scripts\python.exe
2025-08-08 15:26:18,793:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-08 15:26:18,793:INFO:PyCaret required dependencies:
2025-08-08 15:26:18,793:INFO:                 pip: Not installed
2025-08-08 15:26:18,793:INFO:          setuptools: 80.9.0
2025-08-08 15:26:18,793:INFO:             pycaret: 3.3.2
2025-08-08 15:26:18,793:INFO:             IPython: 9.4.0
2025-08-08 15:26:18,793:INFO:          ipywidgets: 8.1.7
2025-08-08 15:26:18,793:INFO:                tqdm: 4.67.1
2025-08-08 15:26:18,793:INFO:               numpy: 1.26.4
2025-08-08 15:26:18,793:INFO:              pandas: 2.1.4
2025-08-08 15:26:18,793:INFO:              jinja2: 3.1.6
2025-08-08 15:26:18,793:INFO:               scipy: 1.11.4
2025-08-08 15:26:18,793:INFO:              joblib: 1.3.2
2025-08-08 15:26:18,793:INFO:             sklearn: 1.4.2
2025-08-08 15:26:18,793:INFO:                pyod: 2.0.5
2025-08-08 15:26:18,794:INFO:            imblearn: 0.13.0
2025-08-08 15:26:18,794:INFO:   category_encoders: 2.7.0
2025-08-08 15:26:18,794:INFO:            lightgbm: 4.6.0
2025-08-08 15:26:18,794:INFO:               numba: 0.61.2
2025-08-08 15:26:18,794:INFO:            requests: 2.32.4
2025-08-08 15:26:18,794:INFO:          matplotlib: 3.7.5
2025-08-08 15:26:18,794:INFO:          scikitplot: 0.3.7
2025-08-08 15:26:18,794:INFO:         yellowbrick: 1.5
2025-08-08 15:26:18,794:INFO:              plotly: 5.24.1
2025-08-08 15:26:18,794:INFO:    plotly-resampler: Not installed
2025-08-08 15:26:18,794:INFO:             kaleido: 1.0.0
2025-08-08 15:26:18,794:INFO:           schemdraw: 0.15
2025-08-08 15:26:18,794:INFO:         statsmodels: 0.14.5
2025-08-08 15:26:18,794:INFO:              sktime: 0.26.0
2025-08-08 15:26:18,794:INFO:               tbats: 1.1.3
2025-08-08 15:26:18,794:INFO:            pmdarima: 2.0.4
2025-08-08 15:26:18,794:INFO:              psutil: 7.0.0
2025-08-08 15:26:18,794:INFO:          markupsafe: 3.0.2
2025-08-08 15:26:18,795:INFO:             pickle5: Not installed
2025-08-08 15:26:18,795:INFO:         cloudpickle: 3.1.1
2025-08-08 15:26:18,795:INFO:         deprecation: 2.1.0
2025-08-08 15:26:18,795:INFO:              xxhash: 3.5.0
2025-08-08 15:26:18,795:INFO:           wurlitzer: Not installed
2025-08-08 15:26:18,795:INFO:PyCaret optional dependencies:
2025-08-08 15:26:18,795:INFO:                shap: 0.44.1
2025-08-08 15:26:18,795:INFO:           interpret: 0.6.9
2025-08-08 15:26:18,795:INFO:                umap: 0.5.7
2025-08-08 15:26:18,795:INFO:     ydata_profiling: 4.14.0
2025-08-08 15:26:18,795:INFO:  explainerdashboard: 0.4.8
2025-08-08 15:26:18,795:INFO:             autoviz: Not installed
2025-08-08 15:26:18,795:INFO:           fairlearn: 0.7.0
2025-08-08 15:26:18,795:INFO:          deepchecks: Not installed
2025-08-08 15:26:18,795:INFO:             xgboost: Not installed
2025-08-08 15:26:18,795:INFO:            catboost: 1.2.8
2025-08-08 15:26:18,796:INFO:              kmodes: 0.12.2
2025-08-08 15:26:18,796:INFO:             mlxtend: 0.23.4
2025-08-08 15:26:18,796:INFO:       statsforecast: 1.5.0
2025-08-08 15:26:18,796:INFO:        tune_sklearn: Not installed
2025-08-08 15:26:18,796:INFO:                 ray: Not installed
2025-08-08 15:26:18,796:INFO:            hyperopt: 0.2.7
2025-08-08 15:26:18,796:INFO:              optuna: 4.4.0
2025-08-08 15:26:18,796:INFO:               skopt: 0.10.2
2025-08-08 15:26:18,796:INFO:              mlflow: 3.2.0
2025-08-08 15:26:18,796:INFO:              gradio: 5.41.1
2025-08-08 15:26:18,796:INFO:             fastapi: 0.116.1
2025-08-08 15:26:18,796:INFO:             uvicorn: 0.35.0
2025-08-08 15:26:18,796:INFO:              m2cgen: 0.10.0
2025-08-08 15:26:18,796:INFO:           evidently: 0.4.40
2025-08-08 15:26:18,796:INFO:               fugue: 0.8.7
2025-08-08 15:26:18,796:INFO:           streamlit: Not installed
2025-08-08 15:26:18,796:INFO:             prophet: Not installed
2025-08-08 15:26:18,796:INFO:None
2025-08-08 15:26:18,796:INFO:Set up data.
2025-08-08 15:26:18,798:INFO:Set up index.
2025-08-08 15:26:18,798:INFO:Assigning column types.
2025-08-08 15:26:18,800:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-08-08 15:26:18,800:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-08-08 15:26:18,800:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,874:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-08-08 15:26:18,874:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,874:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-08-08 15:26:18,874:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,874:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,876:INFO:Preparing preprocessing pipeline...
2025-08-08 15:26:18,876:INFO:Set up simple imputation.
2025-08-08 15:26:18,894:INFO:Finished creating preprocessing pipeline.
2025-08-08 15:26:18,897:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Benja\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Income', 'SpendingScore',
                                             'Savings'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-08 15:26:18,897:INFO:Creating final display dataframe.
2025-08-08 15:26:18,913:INFO:Setup _display_container:                Description                 Value
0               Session id                   123
1      Original data shape              (505, 4)
2   Transformed data shape              (505, 4)
3         Numeric features                     4
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  70bc
2025-08-08 15:26:18,918:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,919:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:18,919:INFO:setup() successfully completed in 0.14s...............
2025-08-08 15:26:20,125:INFO:gpu_param set to False
2025-08-08 15:26:20,126:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:20,127:INFO:Soft dependency imported: kmodes: 0.12.2
2025-08-08 15:26:21,991:INFO:Initializing create_model()
2025-08-08 15:26:21,992:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001F5DA398290>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-08-08 15:26:21,992:INFO:Checking exceptions
2025-08-08 15:26:22,021:INFO:Importing untrained model
2025-08-08 15:26:22,025:INFO:K-Means Clustering Imported successfully
2025-08-08 15:26:22,028:INFO:Fitting Model
2025-08-08 15:26:22,231:INFO:KMeans(algorithm='lloyd', copy_x=True, init='k-means++', max_iter=300,
       n_clusters=4, n_init='auto', random_state=123, tol=0.0001, verbose=0)
2025-08-08 15:26:22,231:INFO:create_models() successfully completed......................................
2025-08-08 15:26:22,234:INFO:Uploading results into container
2025-08-08 15:26:22,235:INFO:Uploading model into container now
2025-08-08 15:26:22,240:INFO:_master_model_container: 1
2025-08-08 15:26:22,240:INFO:_display_container: 2
2025-08-08 15:26:22,241:INFO:KMeans(algorithm='lloyd', copy_x=True, init='k-means++', max_iter=300,
       n_clusters=4, n_init='auto', random_state=123, tol=0.0001, verbose=0)
2025-08-08 15:26:22,241:INFO:create_model() successfully completed......................................
